{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Getting Started with Audio data in Python\"\n",
    "> \"In this article, I am will be explaining some of the modules which can be used to load and manipulate some audio files in python.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [pandas, load, csv, functions, data, dockship, article], \n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required modules\n",
    "\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading audio file as wave object\n",
    "\n",
    "gm_wave = wave.open(, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting wave object into bytes\n",
    "\n",
    "gm_bytes = gm_wave.readframes(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the variable\n",
    "\n",
    "gm_bytes\n",
    "\n",
    "# Output\n",
    "# b'\\x04\\xbb\\x05\\x86\\t\\x10\\x06\\x82\\r\\xe4\\x06\\xda\\x0e...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing into bytes\n",
    "\n",
    "signal_gm = np.frombuffer(gm_bytes, dtype='int16')\n",
    "signal_gm[:10]\n",
    "\n",
    "# Output\n",
    "# array([ -3, -5, -8, -8, -9, -13, -8, -10, -9, -11], dtype=int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frame rate\n",
    "framerate_gm = gm_wave.getframerate()\n",
    "\n",
    "# Show the frame rate\n",
    "framerate_gm\n",
    "\n",
    "# Output\n",
    "# 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating timestamp values\n",
    "\n",
    "time_gm = np.linspace(start=0, stop=len(signal_gm)/framerate_gm, step=len(signal_gm))\n",
    "time_gm[:10]\n",
    "\n",
    "# Output\n",
    "\n",
    "# array([0.00000000e+00, 1.25000117e-04, 2.50000233e-04, ...,\n",
    "       1.34118250e+02, 1.34118375e+02, 1.34118500e+02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Audio Clip\")\n",
    "\n",
    "plt.plot(time_gm, signal_gm)\n",
    "\n",
    "# x and y axis labels\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "# show our plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Create the instance of recognizer\n",
    "recog = sr.Recognizer()\n",
    "\n",
    "# Set the limit of the energy\n",
    "recog.energy_threshold = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate using google api\n",
    "text = recog.recognize_google(audio_data=audio_file, language='en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in audio file\n",
    "audio = sr.AudioFile()\n",
    "\n",
    "# Check type of audio\n",
    "type(audio)\n",
    "\n",
    "# Output\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from AudioFile to AudioData\n",
    "\n",
    "with audio as src:\n",
    "    audio_data = recognizer.record(src)\n",
    "\n",
    "# Check the type\n",
    "type(audio_data)\n",
    "\n",
    "# Output\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave duration and offset as default\n",
    "\n",
    "with clean_support_call as source:\n",
    "    clean_support_call_audio = recognizer.record(source, duration=None, offset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the leopard roar audio file\n",
    "leopard_roar = sr.AudioFile(\"leopard_roar.wav\")\n",
    "\n",
    "# Convert the AudioFile to AudioData\n",
    "with leopard_roar as source:\n",
    "    leopard_roar_audio = recognizer.record(source)\n",
    "\n",
    "# Recognize the AudioData\n",
    "recognizer.recognize_google(leopard_roar_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file with background nosie\n",
    "noisy_support_call = sr.AudioFile(noisy_support_call.wav)\n",
    "\n",
    "with noisy_support_call as source:\n",
    "# Adjust for ambient noise and record\n",
    "    recognizer.adjust_for_ambient_noise(source,duration=0.5)\n",
    "    noisy_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Recognize the audio\n",
    "recognizer.recognize_google(noisy_support_call_audio)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
