{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Important Pandas functions to load data files in Machine Learning Challenges\"\n",
    "> \"In this article I am going to explain some of the important pandas functions which will be used in machine learning challenges.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [pandas, load, csv, functions, data, dockship, article], \n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a python's third-party library that provides computational fast and flexible data structures in manipulating and analyzing tabular, multi-dimensional and time-series data.\n",
    "\n",
    "In most machine learning challenges, the dataset provided will be in the form of .csv files that need to be loaded into the workspace. The loaded dataset will be used in prediction, and predicted values also should be submitted in the form of .csv files as per there submission guidelines.\n",
    "\n",
    "In this article, I will explain some different ways of loading the dataset into your workspace and making an output submission file.\n",
    "\n",
    "The first way is to load the dataset directly without passing any arguments, which is useful when all the columns are used in model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required modules\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()     # To view the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way is to load the dataset using an index_col argument when one of the columns is unique and will not be used in model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_csv('train.csv', index_col='Index')\n",
    "data.head()   # To view the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The type of the index_col argument will be a string when only one column needs to be used as an index; it will be a list of strings when two or more columns need to be used as an index.\n",
    "\n",
    "The Third way is to load the dataset using parse_dates argument when one or more columns in the dataset are of datatype 'datetime[ns]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_csv('train.csv', parse_dates='Date')\n",
    "data.head()     # To view the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The type of the parse_dates argument will be a string when only one column needs to be parsed; it will be a list of strings when two or more columns need to be used as an index.\n",
    "\n",
    "Finally, in the end, after all the model building, model tuning and prediction stuff. You need to save the prediction in the specified format as in the submission guidelines.\n",
    "\n",
    "In most cases, the submission file contains two more columns in which of the column will be the predicted value.\n",
    "\n",
    "For example, if the submission guidelines say that the output should have two columns with column names filename and value, then the code looks similar to this:\n",
    "\n",
    "The variable index contains the filename values, and the variable prediction has the prediction values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "output = pd.DataFrame({'filename': filename, 'value': prediction})\n",
    "output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the index should be False to ensure that the to_csv does not add an extra index column to the output file."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
