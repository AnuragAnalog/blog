{
  
    
        "post0": {
            "title": "Tabular Playground Series Mar 2022",
            "content": "!pip3 install kaggle !pip3 install prophet !pip3 install pystan==2.19.1.1 . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: prophet in /usr/local/lib/python3.7/dist-packages (1.0.1) Requirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.19.1.1) Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.21.5) Requirement already satisfied: holidays&gt;=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.10.5.2) Requirement already satisfied: pandas&gt;=1.0.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.3.5) Requirement already satisfied: convertdate&gt;=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.4.0) Requirement already satisfied: python-dateutil&gt;=2.8.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.8.2) Requirement already satisfied: tqdm&gt;=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (4.63.0) Requirement already satisfied: matplotlib&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (3.2.2) Requirement already satisfied: cmdstanpy==0.9.68 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.9.68) Requirement already satisfied: setuptools-git&gt;=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.2) Requirement already satisfied: LunarCalendar&gt;=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.0.9) Requirement already satisfied: Cython&gt;=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.29.28) Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from cmdstanpy==0.9.68-&gt;prophet) (5.1.0) Requirement already satisfied: pymeeus&lt;=1,&gt;=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate&gt;=2.1.2-&gt;prophet) (0.5.11) Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays&gt;=0.10.2-&gt;prophet) (0.2.1) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays&gt;=0.10.2-&gt;prophet) (1.15.0) Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays&gt;=0.10.2-&gt;prophet) (2.2.3) Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from LunarCalendar&gt;=0.0.9-&gt;prophet) (2018.9) Requirement already satisfied: ephem&gt;=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar&gt;=0.0.9-&gt;prophet) (4.1.3) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (1.4.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (3.0.7) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (0.11.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=2.0.0-&gt;prophet) (3.10.0.2) Requirement already satisfied: pystan==2.19.1.1 in /usr/local/lib/python3.7/dist-packages (2.19.1.1) Requirement already satisfied: Cython!=0.25.1,&gt;=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (0.29.28) Requirement already satisfied: numpy&gt;=1.7 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (1.21.5) . import tqdm import numpy as np import pandas as pd import seaborn as sns from zipfile import ZipFile from prophet import Prophet from matplotlib import pyplot as plt . %matplotlib inline plt.rcParams[&#39;figure.figsize&#39;] = (12, 12) . Before running the below cell, upload your kaggle token, to make sure an error doesn&#39;t popup. . !mkdir ~/.kaggle !cp kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . mkdir: cannot create directory ‘/root/.kaggle’: File exists . !kaggle competitions download -c tabular-playground-series-mar-2022 . tabular-playground-series-mar-2022.zip: Skipping, found more recently modified local copy (use --force to force download) . with ZipFile(&#39;/content/tabular-playground-series-mar-2022.zip&#39;, &#39;r&#39;) as zf: zf.extractall(&#39;./&#39;) . Loading the data . train = pd.read_csv(&#39;train.csv&#39;, index_col=&#39;row_id&#39;, parse_dates=[&#39;time&#39;]) train.head() . time x y direction congestion . row_id . 0 1991-04-01 | 0 | 0 | EB | 70 | . 1 1991-04-01 | 0 | 0 | NB | 49 | . 2 1991-04-01 | 0 | 0 | SB | 24 | . 3 1991-04-01 | 0 | 1 | EB | 18 | . 4 1991-04-01 | 0 | 1 | NB | 60 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train.info() train.describe() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 848835 entries, 0 to 848834 Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 time 848835 non-null datetime64[ns] 1 x 848835 non-null int64 2 y 848835 non-null int64 3 direction 848835 non-null object 4 congestion 848835 non-null int64 dtypes: datetime64[ns](1), int64(3), object(1) memory usage: 38.9+ MB . x y congestion . count 848835.000000 | 848835.000000 | 848835.000000 | . mean 1.138462 | 1.630769 | 47.815305 | . std 0.801478 | 1.089379 | 16.799392 | . min 0.000000 | 0.000000 | 0.000000 | . 25% 0.000000 | 1.000000 | 35.000000 | . 50% 1.000000 | 2.000000 | 47.000000 | . 75% 2.000000 | 3.000000 | 60.000000 | . max 2.000000 | 3.000000 | 100.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; sns.heatmap(train.corr(), annot=True, vmin=-1, vmax=1, cmap=&#39;RdYlGn&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fa74ad97410&gt; . test = pd.read_csv(&#39;test.csv&#39;, index_col=&#39;row_id&#39;, parse_dates=[&#39;time&#39;]) test.head() . time x y direction . row_id . 848835 1991-09-30 12:00:00 | 0 | 0 | EB | . 848836 1991-09-30 12:00:00 | 0 | 0 | NB | . 848837 1991-09-30 12:00:00 | 0 | 0 | SB | . 848838 1991-09-30 12:00:00 | 0 | 1 | EB | . 848839 1991-09-30 12:00:00 | 0 | 1 | NB | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; There are no missing values, in the data. . if train.isna().any().any(): print(train.isna().sum()/train.shape[0]) else: print(&quot;No Missing values&quot;) . No Missing values . Preparation . test[&#39;congestion&#39;] = 0.0 . grouped_train_data = train.groupby([&#39;time&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;]) grouped_test_data = test.groupby([&#39;time&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;]) . train_dict = dict() test_dict = dict() for g in grouped_train_data: if (g[0][1], g[0][2], g[0][3]) in train_dict.keys(): train_dict[(g[0][1], g[0][2], g[0][3])].append((g[0][0], g[1][&#39;congestion&#39;].values[0])) else: train_dict[(g[0][1], g[0][2], g[0][3])] = [(g[0][0], g[1][&#39;congestion&#39;].values[0])] for g in grouped_test_data: if (g[0][1], g[0][2], g[0][3]) in test_dict.keys(): test_dict[(g[0][1], g[0][2], g[0][3])].append((g[0][0], g[1][&#39;congestion&#39;].values[0])) else: test_dict[(g[0][1], g[0][2], g[0][3])] = [(g[0][0], g[1][&#39;congestion&#39;].values[0])] . for idx, li in train_dict.items(): train_dict[idx] = pd.DataFrame(columns=[&#39;ds&#39;, &#39;y&#39;], data=li) for idx, li in test_dict.items(): test_dict[idx] = pd.DataFrame(columns=[&#39;ds&#39;, &#39;y&#39;], data=li).drop([&#39;y&#39;], axis=1) . Modelling . Approach-1 . In this method, I have grouped the data into a number of instances and made the predictions on that instances. . An instance is uniquely identifiable by its a key which is a combination of its cordinates and the direction. . for idx, train_data in tqdm.tqdm(train_dict.items()): model = Prophet() model.fit(train_data) forecast = model.predict(test_dict[idx]) test_dict[idx][&#39;congestion&#39;] = np.round(forecast[&#39;yhat&#39;]) test_dict[idx][&#39;x&#39;] = idx[0] test_dict[idx][&#39;y&#39;] = idx[1] test_dict[idx][&#39;direction&#39;] = idx[2] . 0%| | 0/65 [00:00&lt;?, ?it/s]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 2%|▏ | 1/65 [00:08&lt;08:55, 8.36s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 3%|▎ | 2/65 [00:12&lt;06:23, 6.09s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 5%|▍ | 3/65 [00:20&lt;06:55, 6.70s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 6%|▌ | 4/65 [00:29&lt;07:53, 7.76s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 8%|▊ | 5/65 [00:36&lt;07:21, 7.37s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 9%|▉ | 6/65 [00:41&lt;06:39, 6.77s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 11%|█ | 7/65 [00:48&lt;06:37, 6.85s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 12%|█▏ | 8/65 [00:55&lt;06:24, 6.75s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 14%|█▍ | 9/65 [01:00&lt;05:49, 6.24s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 15%|█▌ | 10/65 [01:06&lt;05:35, 6.10s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 17%|█▋ | 11/65 [01:11&lt;05:08, 5.71s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 18%|█▊ | 12/65 [01:16&lt;04:56, 5.60s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 20%|██ | 13/65 [01:24&lt;05:25, 6.25s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 22%|██▏ | 14/65 [01:28&lt;04:46, 5.63s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 23%|██▎ | 15/65 [01:34&lt;04:46, 5.72s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 25%|██▍ | 16/65 [01:39&lt;04:31, 5.55s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 26%|██▌ | 17/65 [01:45&lt;04:26, 5.55s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 28%|██▊ | 18/65 [01:51&lt;04:29, 5.74s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 29%|██▉ | 19/65 [01:57&lt;04:23, 5.72s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 31%|███ | 20/65 [02:02&lt;04:14, 5.65s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 32%|███▏ | 21/65 [02:06&lt;03:41, 5.03s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 34%|███▍ | 22/65 [02:11&lt;03:46, 5.26s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 35%|███▌ | 23/65 [02:18&lt;03:52, 5.54s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 37%|███▋ | 24/65 [02:21&lt;03:24, 4.99s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 38%|███▊ | 25/65 [02:28&lt;03:43, 5.58s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 40%|████ | 26/65 [02:37&lt;04:09, 6.40s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 42%|████▏ | 27/65 [02:44&lt;04:15, 6.72s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 43%|████▎ | 28/65 [02:51&lt;04:10, 6.78s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 45%|████▍ | 29/65 [02:56&lt;03:44, 6.24s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 46%|████▌ | 30/65 [03:02&lt;03:34, 6.14s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 48%|████▊ | 31/65 [03:08&lt;03:34, 6.29s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 49%|████▉ | 32/65 [03:14&lt;03:17, 5.99s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 51%|█████ | 33/65 [03:19&lt;03:07, 5.85s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 52%|█████▏ | 34/65 [03:23&lt;02:43, 5.28s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 54%|█████▍ | 35/65 [03:29&lt;02:39, 5.33s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 55%|█████▌ | 36/65 [03:35&lt;02:47, 5.76s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 57%|█████▋ | 37/65 [03:41&lt;02:41, 5.77s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 58%|█████▊ | 38/65 [03:46&lt;02:30, 5.57s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 60%|██████ | 39/65 [03:49&lt;02:04, 4.78s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 62%|██████▏ | 40/65 [03:55&lt;02:07, 5.12s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 63%|██████▎ | 41/65 [04:03&lt;02:24, 6.03s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 65%|██████▍ | 42/65 [04:10&lt;02:20, 6.10s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 66%|██████▌ | 43/65 [04:14&lt;02:03, 5.62s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 68%|██████▊ | 44/65 [04:21&lt;02:06, 6.01s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 69%|██████▉ | 45/65 [04:27&lt;02:01, 6.08s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 71%|███████ | 46/65 [04:32&lt;01:48, 5.70s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 72%|███████▏ | 47/65 [04:37&lt;01:39, 5.54s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 74%|███████▍ | 48/65 [04:42&lt;01:29, 5.29s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 75%|███████▌ | 49/65 [04:49&lt;01:34, 5.92s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 77%|███████▋ | 50/65 [04:55&lt;01:25, 5.69s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 78%|███████▊ | 51/65 [05:00&lt;01:17, 5.51s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 80%|████████ | 52/65 [05:04&lt;01:07, 5.20s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 82%|████████▏ | 53/65 [05:11&lt;01:08, 5.74s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 83%|████████▎ | 54/65 [05:17&lt;01:05, 5.93s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 85%|████████▍ | 55/65 [05:23&lt;00:57, 5.77s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 86%|████████▌ | 56/65 [05:28&lt;00:51, 5.73s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 88%|████████▊ | 57/65 [05:35&lt;00:48, 6.03s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 89%|████████▉ | 58/65 [05:40&lt;00:40, 5.78s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 91%|█████████ | 59/65 [05:46&lt;00:33, 5.58s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 92%|█████████▏| 60/65 [05:51&lt;00:28, 5.67s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 94%|█████████▍| 61/65 [05:55&lt;00:20, 5.05s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 95%|█████████▌| 62/65 [05:59&lt;00:14, 4.68s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 97%|█████████▋| 63/65 [06:04&lt;00:09, 4.79s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 98%|█████████▊| 64/65 [06:08&lt;00:04, 4.56s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 100%|██████████| 65/65 [06:11&lt;00:00, 5.72s/it] . preds_semi_final = pd.concat(test_dict.values(), ignore_index=True) preds_final = test.reset_index().merge(preds_semi_final, left_on=[&#39;time&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;], right_on=[&#39;ds&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;])[[&#39;row_id&#39;, &#39;congestion_y&#39;]] . submission = pd.read_csv(&#39;/content/sample_submission.csv&#39;) submission = submission.merge(preds_final, on=&#39;row_id&#39;)[[&#39;row_id&#39;, &#39;congestion_y&#39;]].rename(columns={&#39;congestion_y&#39;: &#39;congestion&#39;}) submission.to_csv(&#39;output.csv&#39;, index=False) . !kaggle competitions submit -c tabular-playground-series-mar-2022 -f output.csv -m &quot;FB Prophet correct 2 with round&quot; . 100% 27.4k/27.4k [00:00&lt;00:00, 150kB/s] Successfully submitted to Tabular Playground Series - Mar 2022 .",
            "url": "https://anuraganalog.github.io/blog/kaggle/fbprophet/jupyter/tps/2022/03/24/Tabular-Playground-Series-Mar-2022-FB-Prophet.html",
            "relUrl": "/kaggle/fbprophet/jupyter/tps/2022/03/24/Tabular-Playground-Series-Mar-2022-FB-Prophet.html",
            "date": " • Mar 24, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "A New Era of Data Analysis in Baseball",
            "content": "1. The Statcast revolution . This is Aaron Judge. Judge is one of the physically largest players in Major League Baseball standing 6 feet 7 inches (2.01 m) tall and weighing 282 pounds (128 kg). He also hit the hardest home run ever recorded. How do we know this? Statcast. . Statcast is a state-of-the-art tracking system that uses high-resolution cameras and radar equipment to measure the precise location and movement of baseballs and baseball players. Introduced in 2015 to all 30 major league ballparks, Statcast data is revolutionizing the game. Teams are engaging in an &quot;arms race&quot; of data analysis, hiring analysts left and right in an attempt to gain an edge over their competition. This video describing the system is incredible. . In this notebook, we&#39;re going to wrangle, analyze, and visualize Statcast data to compare Mr. Judge and another (extremely large) teammate of his. Let&#39;s start by loading the data into our Notebook. There are two CSV files, judge.csv and stanton.csv, both of which contain Statcast data for 2015-2017. We&#39;ll use pandas DataFrames to store this data. Let&#39;s also load our data visualization libraries, matplotlib and seaborn. . import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline # Load Aaron Judge&#39;s Statcast data judge = pd.read_csv(&#39;datasets/judge.csv&#39;) # Load Giancarlo Stanton&#39;s Statcast data stanton = pd.read_csv(&#39;datasets/stanton.csv&#39;) . 2. What can Statcast measure? . The better question might be, what can&#39;t Statcast measure? . Starting with the pitcher, Statcast can measure simple data points such as velocity. At the same time, Statcast digs a whole lot deeper, also measuring the release point and spin rate of every pitch. . Moving on to hitters, Statcast is capable of measuring the exit velocity, launch angle and vector of the ball as it comes off the bat. From there, Statcast can also track the hang time and projected distance that a ball travels. . Let&#39;s inspect the last five rows of the judge DataFrame. You&#39;ll see that each row represents one pitch thrown to a batter. You&#39;ll also see that some columns have esoteric names. If these don&#39;t make sense now, don&#39;t worry. The relevant ones will be explained as necessary. . pd.set_option(&#39;display.max_columns&#39;, None) # Display the last five rows of the Aaron Judge file judge.tail() . pitch_type game_date release_speed release_pos_x release_pos_z player_name batter pitcher events description spin_dir spin_rate_deprecated break_angle_deprecated break_length_deprecated zone des game_type stand p_throws home_team away_team type hit_location bb_type balls strikes game_year pfx_x pfx_z plate_x plate_z on_3b on_2b on_1b outs_when_up inning inning_topbot hc_x hc_y tfs_deprecated tfs_zulu_deprecated pos2_person_id umpire sv_id vx0 vy0 vz0 ax ay az sz_top sz_bot hit_distance_sc launch_speed launch_angle effective_speed release_spin_rate release_extension game_pk pos1_person_id pos2_person_id.1 pos3_person_id pos4_person_id pos5_person_id pos6_person_id pos7_person_id pos8_person_id pos9_person_id release_pos_y estimated_ba_using_speedangle estimated_woba_using_speedangle woba_value woba_denom babip_value iso_value launch_speed_angle at_bat_number pitch_number . 3431 CH | 2016-08-13 | 85.6 | -1.9659 | 5.9113 | Aaron Judge | 592450 | 542882 | NaN | ball | NaN | NaN | NaN | NaN | 14.0 | NaN | R | R | R | NYY | TB | B | NaN | NaN | 0 | 0 | 2016 | -0.379108 | 0.370567 | 0.739 | 1.442 | NaN | NaN | NaN | 0 | 5 | Bot | NaN | NaN | NaN | NaN | 571912.0 | NaN | 160813_144259 | 6.960 | -124.371 | -4.756 | -2.821 | 23.634 | -30.220 | 3.93 | 1.82 | NaN | NaN | NaN | 84.459 | 1552.0 | 5.683 | 448611 | 542882.0 | 571912.0 | 543543.0 | 523253.0 | 446334.0 | 622110.0 | 545338.0 | 595281.0 | 543484.0 | 54.8144 | 0.00 | 0.000 | NaN | NaN | NaN | NaN | NaN | 36 | 1 | . 3432 CH | 2016-08-13 | 87.6 | -1.9318 | 5.9349 | Aaron Judge | 592450 | 542882 | home_run | hit_into_play_score | NaN | NaN | NaN | NaN | 4.0 | Aaron Judge homers (1) on a fly ball to center... | R | R | R | NYY | TB | X | NaN | fly_ball | 1 | 2 | 2016 | -0.295608 | 0.320400 | -0.419 | 3.273 | NaN | NaN | NaN | 2 | 2 | Bot | 130.45 | 14.58 | NaN | NaN | 571912.0 | NaN | 160813_135833 | 4.287 | -127.452 | -0.882 | -1.972 | 24.694 | -30.705 | 4.01 | 1.82 | 446.0 | 108.8 | 27.410 | 86.412 | 1947.0 | 5.691 | 448611 | 542882.0 | 571912.0 | 543543.0 | 523253.0 | 446334.0 | 622110.0 | 545338.0 | 595281.0 | 543484.0 | 54.8064 | 0.98 | 1.937 | 2.0 | 1.0 | 0.0 | 3.0 | 6.0 | 14 | 4 | . 3433 CH | 2016-08-13 | 87.2 | -2.0285 | 5.8656 | Aaron Judge | 592450 | 542882 | NaN | ball | NaN | NaN | NaN | NaN | 14.0 | NaN | R | R | R | NYY | TB | B | NaN | NaN | 0 | 2 | 2016 | -0.668575 | 0.198567 | 0.561 | 0.960 | NaN | NaN | NaN | 2 | 2 | Bot | NaN | NaN | NaN | NaN | 571912.0 | NaN | 160813_135815 | 7.491 | -126.665 | -5.862 | -6.393 | 21.952 | -32.121 | 4.01 | 1.82 | NaN | NaN | NaN | 86.368 | 1761.0 | 5.721 | 448611 | 542882.0 | 571912.0 | 543543.0 | 523253.0 | 446334.0 | 622110.0 | 545338.0 | 595281.0 | 543484.0 | 54.7770 | 0.00 | 0.000 | NaN | NaN | NaN | NaN | NaN | 14 | 3 | . 3434 CU | 2016-08-13 | 79.7 | -1.7108 | 6.1926 | Aaron Judge | 592450 | 542882 | NaN | foul | NaN | NaN | NaN | NaN | 4.0 | NaN | R | R | R | NYY | TB | S | NaN | NaN | 0 | 1 | 2016 | 0.397442 | -0.614133 | -0.803 | 2.742 | NaN | NaN | NaN | 2 | 2 | Bot | NaN | NaN | NaN | NaN | 571912.0 | NaN | 160813_135752 | 1.254 | -116.062 | 0.439 | 5.184 | 21.328 | -39.866 | 4.01 | 1.82 | 9.0 | 55.8 | -24.973 | 77.723 | 2640.0 | 5.022 | 448611 | 542882.0 | 571912.0 | 543543.0 | 523253.0 | 446334.0 | 622110.0 | 545338.0 | 595281.0 | 543484.0 | 55.4756 | 0.00 | 0.000 | NaN | NaN | NaN | NaN | 1.0 | 14 | 2 | . 3435 FF | 2016-08-13 | 93.2 | -1.8476 | 6.0063 | Aaron Judge | 592450 | 542882 | NaN | called_strike | NaN | NaN | NaN | NaN | 8.0 | NaN | R | R | R | NYY | TB | S | NaN | NaN | 0 | 0 | 2016 | -0.823050 | 1.623300 | -0.273 | 2.471 | NaN | NaN | NaN | 2 | 2 | Bot | NaN | NaN | NaN | NaN | 571912.0 | NaN | 160813_135736 | 5.994 | -135.497 | -6.736 | -9.360 | 26.782 | -13.446 | 4.01 | 1.82 | NaN | NaN | NaN | 92.696 | 2271.0 | 6.068 | 448611 | 542882.0 | 571912.0 | 543543.0 | 523253.0 | 446334.0 | 622110.0 | 545338.0 | 595281.0 | 543484.0 | 54.4299 | 0.00 | 0.000 | NaN | NaN | NaN | NaN | NaN | 14 | 1 | . 3. Aaron Judge and Giancarlo Stanton, prolific sluggers . This is Giancarlo Stanton. He is also a very large human being, standing 6 feet 6 inches tall and weighing 245 pounds. Despite not wearing the same jersey as Judge in the pictures provided, in 2018 they will be teammates on the New York Yankees. They are similar in a lot of ways, one being that they hit a lot of home runs. Stanton and Judge led baseball in home runs in 2017, with 59 and 52, respectively. These are exceptional totals - the player in third &quot;only&quot; had 45 home runs. . Stanton and Judge are also different in many ways. One is batted ball events, which is any batted ball that produces a result. This includes outs, hits, and errors. Next, you&#39;ll find the counts of batted ball events for each player in 2017. The frequencies of other events are quite different. . judge_events_2017 = judge[judge[&#39;game_date&#39;] &gt; &#39;2017-01-01&#39;][&#39;events&#39;] print(&quot;Aaron Judge batted ball event totals, 2017:&quot;) print(judge_events_2017.value_counts()) # All of Giancarlo Stanton&#39;s batted ball events in 2017 stanton_events_2017 = stanton[stanton[&#39;game_date&#39;] &gt; &#39;2017-01-01&#39;][&#39;events&#39;] print(&quot; nGiancarlo Stanton batted ball event totals, 2017:&quot;) print(stanton_events_2017.value_counts()) . Aaron Judge batted ball event totals, 2017: strikeout 207 field_out 146 walk 116 single 75 home_run 52 double 24 grounded_into_double_play 15 intent_walk 11 force_out 11 hit_by_pitch 5 sac_fly 4 fielders_choice_out 4 field_error 4 triple 3 strikeout_double_play 1 Name: events, dtype: int64 Giancarlo Stanton batted ball event totals, 2017: field_out 239 strikeout 161 single 77 walk 72 home_run 59 double 32 intent_walk 13 grounded_into_double_play 13 hit_by_pitch 7 force_out 7 field_error 5 sac_fly 3 strikeout_double_play 2 fielders_choice_out 2 pickoff_1b 1 Name: events, dtype: int64 . 4. Analyzing home runs with Statcast data . So Judge walks and strikes out more than Stanton. Stanton flies out more than Judge. But let&#39;s get into their hitting profiles in more detail. Two of the most groundbreaking Statcast metrics are launch angle and exit velocity: . Launch angle: the vertical angle at which the ball leaves a player&#39;s bat | Exit velocity: the speed of the baseball as it comes off the bat | . This new data has changed the way teams value both hitters and pitchers. Why? As per the Washington Post: . Balls hit with a high launch angle are more likely to result in a hit. Hit fast enough and at the right angle, they become home runs. . Let&#39;s look at exit velocity vs. launch angle and let&#39;s focus on home runs only (2015-2017). The first two plots show data points. The second two show smoothed contours to represent density. . judge_hr = judge[judge[&#39;events&#39;] == &#39;home_run&#39;] stanton_hr = stanton[stanton[&#39;events&#39;] == &#39;home_run&#39;] # Create a figure with two scatter plots of launch speed vs. launch angle, one for each player&#39;s home runs fig1, axs1 = plt.subplots(ncols=2, sharex=True, sharey=True) sns.regplot(x=&#39;launch_speed&#39;, y=&#39;launch_angle&#39;, fit_reg=False, color=&#39;tab:blue&#39;, data=judge_hr, ax=axs1[0]).set_title(&#39;Aaron Judge nHome Runs, 2015-2017&#39;) sns.regplot(x=&#39;launch_speed&#39;, y=&#39;launch_angle&#39;, fit_reg=False, color=&#39;tab:blue&#39;, data=stanton_hr, ax=axs1[1]).set_title(&#39;Giancarlo Stanton nHome Runs, 2015-2017&#39;) # Create a figure with two KDE plots of launch speed vs. launch angle, one for each player&#39;s home runs fig2, axs2 = plt.subplots(ncols=2, sharex=True, sharey=True) sns.kdeplot(judge_hr[&#39;launch_speed&#39;], judge_hr[&#39;launch_angle&#39;], cmap=&quot;Blues&quot;, shade=True, shade_lowest=False, ax=axs2[0]).set_title(&#39;Aaron Judge nHome Runs, 2015-2017&#39;) sns.kdeplot(stanton_hr[&#39;launch_speed&#39;], stanton_hr[&#39;launch_angle&#39;], cmap=&quot;Blues&quot;, shade=True, shade_lowest=False, ax=axs2[1]).set_title(&#39;Giancarlo Stanton nHome Runs, 2015-2017&#39;) . Text(0.5,1,&#39;Giancarlo Stanton nHome Runs, 2015-2017&#39;) . 5. Home runs by pitch velocity . It appears that Stanton hits his home runs slightly lower and slightly harder than Judge, though this needs to be taken with a grain of salt given the small sample size of home runs. . Not only does Statcast measure the velocity of the ball coming off of the bat, it measures the velocity of the ball coming out of the pitcher&#39;s hand and begins its journey towards the plate. We can use this data to compare Stanton and Judge&#39;s home runs in terms of pitch velocity. Next you&#39;ll find box plots displaying the five-number summaries for each player: minimum, first quartile, median, third quartile, and maximum. . judge_stanton_hr = pd.concat([judge_hr, stanton_hr], axis=0) # Create a boxplot that describes the pitch velocity of each player&#39;s home runs sns.boxplot(judge_stanton_hr[&#39;release_speed&#39;]).set_title(&#39;Home Runs, 2015-2017&#39;) . Text(0.5,1,&#39;Home Runs, 2015-2017&#39;) . 6. Home runs by pitch location (I) . So Judge appears to hit his home runs off of faster pitches than Stanton. We might call Judge a fastball hitter. Stanton appears agnostic to pitch speed and likely pitch movement since slower pitches (e.g. curveballs, sliders, and changeups) tend to have more break. Statcast does track pitch movement and type but let&#39;s move on to something else: pitch location. Statcast tracks the zone the pitch is in when it crosses the plate. The zone numbering looks like this (from the catcher&#39;s point of view): . . We can plot this using a 2D histogram. For simplicity, let&#39;s only look at strikes, which gives us a 9x9 grid. We can view each zone as coordinates on a 2D plot, the bottom left corner being (1,1) and the top right corner being (3,3). Let&#39;s set up a function to assign x-coordinates to each pitch. . def assign_x_coord(row): &quot;&quot;&quot; Assigns an x-coordinate to Statcast&#39;s strike zone numbers. Zones 11, 12, 13, and 14 are ignored for plotting simplicity. &quot;&quot;&quot; # Left third of strike zone if row.zone in [1, 4, 7]: return 1 # Middle third of strike zone if row.zone in [2, 5, 8]: return 2 # Right third of strike zone if row.zone in [3, 6, 9]: return 3 . 7. Home runs by pitch location (II) . And let&#39;s do the same but for y-coordinates. . def assign_y_coord(row): &quot;&quot;&quot; Assigns a y-coordinate to Statcast&#39;s strike zone numbers. Zones 11, 12, 13, and 14 are ignored for plotting simplicity. &quot;&quot;&quot; # Upper third of strike zone if row.zone in [1, 2, 3]: return 3 # Middle third of strike zone if row.zone in [4, 5, 6]: return 2 # Lower third of strike zone if row.zone in [7, 8, 9]: return 1 . 8. Aaron Judge&#39;s home run zone . Now we can apply the functions we&#39;ve created then construct our 2D histograms. First, for Aaron Judge (again, for pitches in the strike zone that resulted in home runs). . judge_strike_hr = judge_hr.copy().loc[judge_hr.zone &lt;= 9] # Assign Cartesian coordinates to pitches in the strike zone for Judge home runs judge_strike_hr[&#39;zone_x&#39;] = judge_strike_hr.apply(assign_x_coord, axis=1) judge_strike_hr[&#39;zone_y&#39;] = judge_strike_hr.apply(assign_y_coord, axis=1) # Plot Judge&#39;s home run zone as a 2D histogram with a colorbar plt.hist2d(judge_strike_hr[&#39;zone_x&#39;], judge_strike_hr[&#39;zone_y&#39;], bins = 3, cmap=&#39;Blues&#39;) plt.title(&#39;Aaron Judge Home Runs on n Pitches in the Strike Zone, 2015-2017&#39;) plt.gca().get_xaxis().set_visible(False) plt.gca().get_yaxis().set_visible(False) cb = plt.colorbar() cb.set_label(&#39;Counts in Bin&#39;) . 9. Giancarlo Stanton&#39;s home run zone . And now for Giancarlo Stanton. . stanton_strike_hr = stanton_hr.copy().loc[stanton_hr.zone &lt;= 9] # Assign Cartesian coordinates to pitches in the strike zone for Stanton home runs ome runs stanton_strike_hr[&#39;zone_x&#39;] = stanton_strike_hr.apply(assign_x_coord, axis=1) stanton_strike_hr[&#39;zone_y&#39;] = stanton_strike_hr.apply(assign_y_coord, axis=1) # Plot Stanton&#39;s home run zone as a 2D histogram with a colorbar plt.hist2d(stanton_strike_hr[&#39;zone_x&#39;], stanton_strike_hr[&#39;zone_y&#39;], bins = 3, cmap=&#39;Blues&#39;) plt.title(&#39;Giancarlo Stanton Home Runs on n Pitches in the Strike Zone, 2015-2017&#39;) plt.gca().get_xaxis().set_visible(False) plt.gca().get_yaxis().set_visible(False) cb = plt.colorbar() cb.set_label(&#39;Counts in Bin&#39;) . File &#34;&lt;ipython-input-286-e2275b3e6291&gt;&#34;, line 5 ome runs ^ SyntaxError: invalid syntax . 10. Should opposing pitchers be scared? . A few takeaways: . Stanton does not hit many home runs on pitches in the upper third of the strike zone. | Like pretty much every hitter ever, both players love pitches in the horizontal and vertical middle of the plate. | Judge&#39;s least favorite home run pitch appears to be high-away while Stanton&#39;s appears to be low-away. | If we were to describe Stanton&#39;s home run zone, it&#39;d be middle-inside. Judge&#39;s home run zone is much more spread out. | . The grand takeaway from this whole exercise: Aaron Judge and Giancarlo Stanton are not identical despite their superficial similarities. In terms of home runs, their launch profiles, as well as their pitch speed and location preferences, are different. . Should opposing pitchers still be scared? . should_pitchers_be_scared = True .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/python/2020/04/08/A-New-Era-of-Data-Analysis-in-Baseball.html",
            "relUrl": "/datacamp/projects/python/2020/04/08/A-New-Era-of-Data-Analysis-in-Baseball.html",
            "date": " • Apr 8, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Visualizing COVID-19",
            "content": "1. From epidemic to pandemic . In December 2019, COVID-19 coronavirus was first identified in the Wuhan region of China. By March 11, 2020, the World Health Organization (WHO) categorized the COVID-19 outbreak as a pandemic. A lot has happened in the months in between with major outbreaks in Iran, South Korea, and Italy. . We know that COVID-19 spreads through respiratory droplets, such as through coughing, sneezing, or speaking. But, how quickly did the virus spread across the globe? And, can we see any effect from country-wide policies, like shutdowns and quarantines? . Fortunately, organizations around the world have been collecting data so that governments can monitor and learn from this pandemic. Notably, the Johns Hopkins University Center for Systems Science and Engineering created a publicly available data repository to consolidate this data from sources like the WHO, the Centers for Disease Control and Prevention (CDC), and the Ministry of Health from multiple countries. . In this notebook, you will visualize COVID-19 data from the first several weeks of the outbreak to see at what point this virus became a global pandemic. . Please note that information and data regarding COVID-19 is frequently being updated. The data used in this project was pulled on March 17, 2020, and should not be considered to be the most up to date data available. . library(readr) library(ggplot2) library(dplyr) # Read datasets/confirmed_cases_worldwide.csv into confirmed_cases_worldwide confirmed_cases_worldwide &lt;- read_csv(&#39;datasets/confirmed_cases_worldwide.csv&#39;) # See the result confirmed_cases_worldwide . Parsed with column specification: cols( date = col_date(format = &#34;&#34;), cum_cases = col_double() ) . A spec_tbl_df: 56 x 2 datecum_cases . &lt;date&gt;&lt;dbl&gt; . 2020-01-22 | 555 | . 2020-01-23 | 653 | . 2020-01-24 | 941 | . 2020-01-25 | 1434 | . 2020-01-26 | 2118 | . 2020-01-27 | 2927 | . 2020-01-28 | 5578 | . 2020-01-29 | 6166 | . 2020-01-30 | 8234 | . 2020-01-31 | 9927 | . 2020-02-01 | 12038 | . 2020-02-02 | 16787 | . 2020-02-03 | 19881 | . 2020-02-04 | 23892 | . 2020-02-05 | 27635 | . 2020-02-06 | 30817 | . 2020-02-07 | 34391 | . 2020-02-08 | 37120 | . 2020-02-09 | 40150 | . 2020-02-10 | 42762 | . 2020-02-11 | 44802 | . 2020-02-12 | 45221 | . 2020-02-13 | 60368 | . 2020-02-14 | 66885 | . 2020-02-15 | 69030 | . 2020-02-16 | 71224 | . 2020-02-17 | 73258 | . 2020-02-18 | 75136 | . 2020-02-19 | 75639 | . 2020-02-20 | 76197 | . 2020-02-21 | 76823 | . 2020-02-22 | 78579 | . 2020-02-23 | 78965 | . 2020-02-24 | 79568 | . 2020-02-25 | 80413 | . 2020-02-26 | 81395 | . 2020-02-27 | 82754 | . 2020-02-28 | 84120 | . 2020-02-29 | 86011 | . 2020-03-01 | 88369 | . 2020-03-02 | 90306 | . 2020-03-03 | 92840 | . 2020-03-04 | 95120 | . 2020-03-05 | 97882 | . 2020-03-06 | 101784 | . 2020-03-07 | 105821 | . 2020-03-08 | 109795 | . 2020-03-09 | 113561 | . 2020-03-10 | 118592 | . 2020-03-11 | 125865 | . 2020-03-12 | 128343 | . 2020-03-13 | 145193 | . 2020-03-14 | 156097 | . 2020-03-15 | 167449 | . 2020-03-16 | 181531 | . 2020-03-17 | 197146 | . 2. Confirmed cases throughout the world . The table above shows the cumulative confirmed cases of COVID-19 worldwide by date. Just reading numbers in a table makes it hard to get a sense of the scale and growth of the outbreak. Let&#39;s draw a line plot to visualize the confirmed cases worldwide. . # Label the y-axis ggplot(data=confirmed_cases_worldwide, aes(x=date, y=cum_cases)) + geom_line() + geom_point() + ylab(&quot;Cumulative confirmed cases&quot;) . 3. China compared to the rest of the world . The y-axis in that plot is pretty scary, with the total number of confirmed cases around the world approaching 200,000. Beyond that, some weird things are happening: there is an odd jump in mid February, then the rate of new cases slows down for a while, then speeds up again in March. We need to dig deeper to see what is happening. . Early on in the outbreak, the COVID-19 cases were primarily centered in China. Let&#39;s plot confirmed COVID-19 cases in China and the rest of the world separately to see if it gives us any insight. . We&#39;ll build on this plot in future tasks. One thing that will be important for the following tasks is that you add aesthetics within the line geometry of your ggplot, rather than making them global aesthetics. . confirmed_cases_china_vs_world &lt;- read_csv(&#39;datasets/confirmed_cases_china_vs_world.csv&#39;) # See the result confirmed_cases_china_vs_world # Draw a line plot of cumulative cases vs. date, grouped and colored by is_china # Define aesthetics within the line geom plt_cum_confirmed_cases_china_vs_world &lt;- ggplot(data=confirmed_cases_china_vs_world) + geom_line(aes(x=date, y=cum_cases, group=is_china, color=is_china)) + ylab(&quot;Cumulative confirmed cases&quot;) # See the plot plt_cum_confirmed_cases_china_vs_world . Parsed with column specification: cols( is_china = col_character(), date = col_date(format = &#34;&#34;), cases = col_double(), cum_cases = col_double() ) . A spec_tbl_df: 112 x 4 is_chinadatecasescum_cases . &lt;chr&gt;&lt;date&gt;&lt;dbl&gt;&lt;dbl&gt; . China | 2020-01-22 | 548 | 548 | . China | 2020-01-23 | 95 | 643 | . China | 2020-01-24 | 277 | 920 | . China | 2020-01-25 | 486 | 1406 | . China | 2020-01-26 | 669 | 2075 | . China | 2020-01-27 | 802 | 2877 | . China | 2020-01-28 | 2632 | 5509 | . China | 2020-01-29 | 578 | 6087 | . China | 2020-01-30 | 2054 | 8141 | . China | 2020-01-31 | 1661 | 9802 | . China | 2020-02-01 | 2089 | 11891 | . China | 2020-02-02 | 4739 | 16630 | . China | 2020-02-03 | 3086 | 19716 | . China | 2020-02-04 | 3991 | 23707 | . China | 2020-02-05 | 3733 | 27440 | . China | 2020-02-06 | 3147 | 30587 | . China | 2020-02-07 | 3523 | 34110 | . China | 2020-02-08 | 2704 | 36814 | . China | 2020-02-09 | 3015 | 39829 | . China | 2020-02-10 | 2525 | 42354 | . China | 2020-02-11 | 2032 | 44386 | . China | 2020-02-12 | 373 | 44759 | . China | 2020-02-13 | 15136 | 59895 | . China | 2020-02-14 | 6463 | 66358 | . China | 2020-02-15 | 2055 | 68413 | . China | 2020-02-16 | 2100 | 70513 | . China | 2020-02-17 | 1921 | 72434 | . China | 2020-02-18 | 1777 | 74211 | . China | 2020-02-19 | 408 | 74619 | . China | 2020-02-20 | 458 | 75077 | . ... | ... | ... | ... | . Not China | 2020-02-17 | 113 | 824 | . Not China | 2020-02-18 | 101 | 925 | . Not China | 2020-02-19 | 95 | 1020 | . Not China | 2020-02-20 | 100 | 1120 | . Not China | 2020-02-21 | 153 | 1273 | . Not China | 2020-02-22 | 305 | 1578 | . Not China | 2020-02-23 | 365 | 1943 | . Not China | 2020-02-24 | 384 | 2327 | . Not China | 2020-02-25 | 332 | 2659 | . Not China | 2020-02-26 | 570 | 3229 | . Not China | 2020-02-27 | 925 | 4154 | . Not China | 2020-02-28 | 1038 | 5192 | . Not China | 2020-02-29 | 1463 | 6655 | . Not China | 2020-03-01 | 1782 | 8437 | . Not China | 2020-03-02 | 1733 | 10170 | . Not China | 2020-03-03 | 2409 | 12579 | . Not China | 2020-03-04 | 2155 | 14734 | . Not China | 2020-03-05 | 2611 | 17345 | . Not China | 2020-03-06 | 3749 | 21094 | . Not China | 2020-03-07 | 3957 | 25051 | . Not China | 2020-03-08 | 3921 | 28972 | . Not China | 2020-03-09 | 3729 | 32701 | . Not China | 2020-03-10 | 5004 | 37705 | . Not China | 2020-03-11 | 7239 | 44944 | . Not China | 2020-03-12 | 2467 | 47411 | . Not China | 2020-03-13 | 16837 | 64248 | . Not China | 2020-03-14 | 10872 | 75120 | . Not China | 2020-03-15 | 11326 | 86446 | . Not China | 2020-03-16 | 14052 | 100498 | . Not China | 2020-03-17 | 15590 | 116088 | . 4. Let&#39;s annotate! . Wow! The two lines have very different shapes. In February, the majority of cases were in China. That changed in March when it really became a global outbreak: around March 14, the total number of cases outside China overtook the cases inside China. This was days after the WHO declared a pandemic. . There were a couple of other landmark events that happened during the outbreak. For example, the huge jump in the China line on February 13, 2020 wasn&#39;t just a bad day regarding the outbreak; China changed the way it reported figures on that day (CT scans were accepted as evidence for COVID-19, rather than only lab tests). . By annotating events like this, we can better interpret changes in the plot. . who_events &lt;- tribble( ~ date, ~ event, &quot;2020-01-30&quot;, &quot;Global health nemergency declared&quot;, &quot;2020-03-11&quot;, &quot;Pandemic ndeclared&quot;, &quot;2020-02-13&quot;, &quot;China reporting nchange&quot; ) %&gt;% mutate(date = as.Date(date)) # Using who_events, add vertical dashed lines with an xintercept at date # and text at date, labeled by event, and at 100000 on the y-axis plt_cum_confirmed_cases_china_vs_world + geom_vline(data=who_events, linetype=&#39;dashed&#39;, aes(xintercept=date)) + geom_text(data=who_events, y=1e+05, aes(x=date, label=event)) . 5. Adding a trend line to China . When trying to assess how big future problems are going to be, we need a measure of how fast the number of cases is growing. A good starting point is to see if the cases are growing faster or slower than linearly. . There is a clear surge of cases around February 13, 2020, with the reporting change in China. However, a couple of days after, the growth of cases in China slows down. How can we describe COVID-19&#39;s growth in China after February 15, 2020? . china_after_feb15 &lt;- filter(confirmed_cases_china_vs_world, date &gt;= &quot;2020-02-15&quot; &amp; is_china == &#39;China&#39;) # Using china_after_feb15, draw a line plot cum_cases vs. date # Add a smooth trend line using linear regression, no error bars ggplot(data=china_after_feb15, aes(x=date, y=cum_cases)) + geom_line() + geom_smooth(method=&#39;lm&#39;, se=FALSE) + ylab(&quot;Cumulative confirmed cases&quot;) . `geom_smooth()` using formula &#39;y ~ x&#39; . 6. And the rest of the world? . From the plot above, the growth rate in China is slower than linear. That&#39;s great news because it indicates China has at least somewhat contained the virus in late February and early March. . How does the rest of the world compare to linear growth? . not_china &lt;- filter(confirmed_cases_china_vs_world, is_china != &#39;China&#39;) # Using not_china, draw a line plot cum_cases vs. date # Add a smooth trend line using linear regression, no error bars plt_not_china_trend_lin &lt;- ggplot(data=not_china, aes(x=date, y=cum_cases)) + geom_line() + geom_smooth(method=&#39;lm&#39;, se=FALSE) + ylab(&quot;Cumulative confirmed cases&quot;) # See the result plt_not_china_trend_lin . `geom_smooth()` using formula &#39;y ~ x&#39; . 7. Adding a logarithmic scale . From the plot above, we can see a straight line does not fit well at all, and the rest of the world is growing much faster than linearly. What if we added a logarithmic scale to the y-axis? . plt_not_china_trend_lin + scale_y_log10(TRUE) . `geom_smooth()` using formula &#39;y ~ x&#39; . 8. Which countries outside of China have been hit hardest? . With the logarithmic scale, we get a much closer fit to the data. From a data science point of view, a good fit is great news. Unfortunately, from a public health point of view, that means that cases of COVID-19 in the rest of the world are growing at an exponential rate, which is terrible news. . Not all countries are being affected by COVID-19 equally, and it would be helpful to know where in the world the problems are greatest. Let&#39;s find the countries outside of China with the most confirmed cases in our dataset. . confirmed_cases_by_country &lt;- read_csv(&quot;datasets/confirmed_cases_by_country.csv&quot;) glimpse(confirmed_cases_by_country) # Group by country, summarize to calculate total cases, find the top 7 top_countries_by_total_cases &lt;- confirmed_cases_by_country %&gt;% group_by(country) %&gt;% summarise(confirmed_cases_by_country = max(cum_cases)) %&gt;% top_n(7) # See the result top_countries_by_total_cases . Parsed with column specification: cols( country = col_character(), province = col_character(), date = col_date(format = &#34;&#34;), cases = col_double(), cum_cases = col_double() ) . Observations: 13,272 Variables: 5 $ country &lt;chr&gt; &#34;Afghanistan&#34;, &#34;Albania&#34;, &#34;Algeria&#34;, &#34;Andorra&#34;, &#34;Antigua ... $ province &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... $ date &lt;date&gt; 2020-01-22, 2020-01-22, 2020-01-22, 2020-01-22, 2020-01-... $ cases &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... $ cum_cases &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... . Selecting by confirmed_cases_by_country . A tibble: 7 x 2 countryconfirmed_cases_by_country . &lt;chr&gt;&lt;dbl&gt; . France | 7699 | . Germany | 9257 | . Iran | 16169 | . Italy | 31506 | . Korea, South | 8320 | . Spain | 11748 | . US | 6421 | . 9. Plotting hardest hit countries as of Mid-March 2020 . Even though the outbreak was first identified in China, there is only one country from East Asia (South Korea) in the above table. Four of the listed countries (France, Germany, Italy, and Spain) are in Europe and share borders. To get more context, we can plot these countries&#39; confirmed cases over time. . Finally, congratulations on getting to the last step! If you would like to continue making visualizations or find the hardest hit countries as of today, you can do your own analyses with the latest data available here. . confirmed_cases_top7_outside_china = read_csv(&#39;datasets/confirmed_cases_top7_outside_china.csv&#39;) # glimpse(confirmed_cases_top7_outside_china) # Using confirmed_cases_top7_outside_china, draw a line plot of # cum_cases vs. date, grouped and colored by country ggplot(data=confirmed_cases_top7_outside_china, aes(x=date, y=cum_cases)) + geom_line(aes(color=country, group=country)) + ylab(&quot;Cumulative confirmed cases&quot;) . Parsed with column specification: cols( country = col_character(), date = col_date(format = &#34;&#34;), cum_cases = col_double() ) . Observations: 2,030 Variables: 3 $ country &lt;chr&gt; &#34;Germany&#34;, &#34;Iran&#34;, &#34;Italy&#34;, &#34;Korea, South&#34;, &#34;Spain&#34;, &#34;US&#34;... $ date &lt;date&gt; 2020-02-18, 2020-02-18, 2020-02-18, 2020-02-18, 2020-02-... $ cum_cases &lt;dbl&gt; 16, 0, 3, 31, 2, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, ... .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/r/2020/04/03/Visualizing-COVID-19.html",
            "relUrl": "/datacamp/projects/r/2020/04/03/Visualizing-COVID-19.html",
            "date": " • Apr 3, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Introduction to DataCamp Projects(R)",
            "content": "1. This is a Jupyter notebook! . A Jupyter notebook is a document that contains text cells (what you&#39;re reading right now) and code cells. What is special with a notebook is that it&#39;s interactive: You can change or add code cells, and then run a cell by first selecting it and then clicking the run cell button above ( ▶| Run ) or hitting ctrl + enter. . . The result will be displayed directly in the notebook. You could use a notebook as a simple calculator. For example, it&#39;s estimated that on average 256 children were born every minute in 2016. The code cell below calculates how many children were born on average on a day. . 256 * 60 * 24 # Children × minutes × hours . 368640 2. Put any code in code cells . But a code cell can contain much more than a simple one-liner! This is a notebook running R and you can put any R code in a code cell (but notebooks can run other languages too, like python). Below is a code cell where we define a whole new function (greet). To show the output of greet we can run it anywhere and the result is always printed out at the end of the code cell. . greet &lt;- function(first_name, last_name) { paste(&quot;My name is &quot;, last_name, &quot;, &quot;, first_name, &quot; &quot;, last_name, &quot;!&quot;, sep = &quot;&quot;) } # Replace with your first and last name. # That is, unless your name is already James Bond. greet(&quot;James&quot;, &quot;Bond&quot;) . &#39;My name is Bond, James Bond!&#39; 3. Jupyter notebooks &#9825; data . We&#39;ve seen that notebooks can display basic objects such as numbers and strings. But notebooks also support the objects used in data science, which makes them great for interactive data analysis! . For example, below we create a data frame by reading in a csv-file with the average global temperature for the years 1850 to 2016. If we look at the head of this data frame the notebook will render it as a nice-looking table. . global_temp &lt;- read.csv(&quot;datasets/global_temperature.csv&quot;) # Take a look at the first datapoints global_temp[1,] . A data.frame: 1 x 2 yeardegrees_celsius . &lt;int&gt;&lt;dbl&gt; . 1850 | 7.74 | . 4. Jupyter notebooks &#9825; plots . Tables are nice but — as the saying goes — &quot;a plot can show a thousand data points&quot;. Notebooks handle plots as well and all plots created in code cells will automatically be displayed inline. . Let&#39;s take a look at the global temperature for the last 150 years. . plot(global_temp$year, global_temp$degrees_celsius, type = &quot;l&quot;, col = &quot;forestgreen&quot;, xlab = &quot;Year&quot;, ylab = &quot;Celsius&quot;) . 5. Jupyter notebooks &#9825; Data Science . Tables and plots are the most common outputs when doing data science and, as these outputs are rendered inline, notebooks works great not only for doing a data analysis but also for showing a data analysis. A finished notebook contains both the result and the code that produced it. This is useful when you want to share your findings or if you need to update your analysis with new data. . Let&#39;s add some advanced data analysis to our notebook! For example, this (slightly complicated) code forecasts the global temperature 50 years into the future using an exponential smoothing state space model (ets). . Note: Global temperature is a complex phenomenon and exponential smoothing is likely not a good model here. This is just an example of how easy it is to do (and show) complex forecasting in a Jupyter notebook. . library(forecast) library(ggplot2) # Converting global_temp into a time series (ts) object. global_temp_ts &lt;- ts(global_temp$degrees_celsius, start = global_temp$year[1]) # Forecasting global temperature 50 years into the future # using an exponential smoothing state space model (ets). temperature_forecast &lt;- forecast( ets(global_temp_ts), h = 50) # Plotting the forecast plot(temperature_forecast, type=&#39;l&#39;) . 6. Goodbye for now! . This was just a short introduction to Jupyter notebooks, an open source technology that is increasingly used for data science and analysis. I hope you enjoyed it! :) . I_am_ready &lt;- TRUE # Ps. # Feel free to try out any other stuff in this notebook. # It&#39;s all yours! .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/r/2020/03/01/Introduction-to-DataCamp-Projects.html",
            "relUrl": "/datacamp/projects/r/2020/03/01/Introduction-to-DataCamp-Projects.html",
            "date": " • Mar 1, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "A Network Analysis of Game of Thrones",
            "content": "1. Winter is Coming. Let&#39;s load the dataset ASAP! . If you haven&#39;t heard of Game of Thrones, then you must be really good at hiding. Game of Thrones is the hugely popular television series by HBO based on the (also) hugely popular book series A Song of Ice and Fire by George R.R. Martin. In this notebook, we will analyze the co-occurrence network of the characters in the Game of Thrones books. Here, two characters are considered to co-occur if their names appear in the vicinity of 15 words from one another in the books. . . This dataset constitutes a network and is given as a text file describing the edges between characters, with some attributes attached to each edge. Let&#39;s start by loading in the data for the first book A Game of Thrones and inspect it. . import pandas as pd # Reading in datasets/book1.csv book1 = pd.read_csv(&#39;datasets/book1.csv&#39;) # Printing out the head of the dataset book1.head() . Source Target Type weight book . 0 Addam-Marbrand | Jaime-Lannister | Undirected | 3 | 1 | . 1 Addam-Marbrand | Tywin-Lannister | Undirected | 6 | 1 | . 2 Aegon-I-Targaryen | Daenerys-Targaryen | Undirected | 5 | 1 | . 3 Aegon-I-Targaryen | Eddard-Stark | Undirected | 4 | 1 | . 4 Aemon-Targaryen-(Maester-Aemon) | Alliser-Thorne | Undirected | 4 | 1 | . 2. Time for some Network of Thrones . The resulting DataFrame book1 has 5 columns: Source, Target, Type, weight, and book. Source and target are the two nodes that are linked by an edge. A network can have directed or undirected edges and in this network all the edges are undirected. The weight attribute of every edge tells us the number of interactions that the characters have had over the book, and the book column tells us the book number. . Once we have the data loaded as a pandas DataFrame, it&#39;s time to create a network. We will use networkx, a network analysis library, and create a graph object for the first book. . import networkx as nx # Creating an empty graph object G_book1 = nx.Graph() . 3. Populate the network with the DataFrame . Currently, the graph object G_book1 is empty. Let&#39;s now populate it with the edges from book1. And while we&#39;re at it, let&#39;s load in the rest of the books too! . for i, se in book1.iterrows(): G_book1.add_edge(se[&#39;Source&#39;], se[&#39;Target&#39;], weights=se[&#39;weight&#39;]) # Creating a list of networks for all the books books = [G_book1] book_fnames = [&#39;datasets/book2.csv&#39;, &#39;datasets/book3.csv&#39;, &#39;datasets/book4.csv&#39;, &#39;datasets/book5.csv&#39;] for book_fname in book_fnames: book = pd.read_csv(book_fname) G_book = nx.Graph() for _, edge in book.iterrows(): G_book.add_edge(edge[&#39;Source&#39;], edge[&#39;Target&#39;], weight=edge[&#39;weight&#39;]) books.append(G_book) . 4. The most important character in Game of Thrones . Is it Jon Snow, Tyrion, Daenerys, or someone else? Let&#39;s see! Network science offers us many different metrics to measure the importance of a node in a network. Note that there is no &quot;correct&quot; way of calculating the most important node in a network, every metric has a different meaning. . First, let&#39;s measure the importance of a node in a network by looking at the number of neighbors it has, that is, the number of nodes it is connected to. For example, an influential account on Twitter, where the follower-followee relationship forms the network, is an account which has a high number of followers. This measure of importance is called degree centrality. . Using this measure, let&#39;s extract the top ten important characters from the first book (book[0]) and the fifth book (book[4]). . deg_cen_book1 = nx.degree_centrality(books[0]) # Calculating the degree centrality of book 5 deg_cen_book5 = nx.degree_centrality(books[4]) # Sorting the dictionaries according to their degree centrality and storing the top 10 sorted_deg_cen_book1 = sorted(deg_cen_book1.items(), key = lambda x:x[1], reverse=True)[:10] # Sorting the dictionaries according to their degree centrality and storing the top 10 sorted_deg_cen_book5 = sorted(deg_cen_book5.items(), key = lambda x:x[1], reverse=True)[:10] # Printing out the top 10 of book1 and book5 print(sorted_deg_cen_book1) print(sorted_deg_cen_book5) . [(&#39;Eddard-Stark&#39;, 0.3548387096774194), (&#39;Robert-Baratheon&#39;, 0.2688172043010753), (&#39;Tyrion-Lannister&#39;, 0.24731182795698928), (&#39;Catelyn-Stark&#39;, 0.23118279569892475), (&#39;Jon-Snow&#39;, 0.19892473118279572), (&#39;Robb-Stark&#39;, 0.18817204301075272), (&#39;Sansa-Stark&#39;, 0.18817204301075272), (&#39;Bran-Stark&#39;, 0.17204301075268819), (&#39;Cersei-Lannister&#39;, 0.16129032258064518), (&#39;Joffrey-Baratheon&#39;, 0.16129032258064518)] [(&#39;Jon-Snow&#39;, 0.1962025316455696), (&#39;Daenerys-Targaryen&#39;, 0.18354430379746836), (&#39;Stannis-Baratheon&#39;, 0.14873417721518986), (&#39;Tyrion-Lannister&#39;, 0.10443037974683544), (&#39;Theon-Greyjoy&#39;, 0.10443037974683544), (&#39;Cersei-Lannister&#39;, 0.08860759493670886), (&#39;Barristan-Selmy&#39;, 0.07911392405063292), (&#39;Hizdahr-zo-Loraq&#39;, 0.06962025316455696), (&#39;Asha-Greyjoy&#39;, 0.056962025316455694), (&#39;Melisandre&#39;, 0.05379746835443038)] . 5. The evolution of character importance . According to degree centrality, the most important character in the first book is Eddard Stark but he is not even in the top 10 of the fifth book. The importance of characters changes over the course of five books because, you know, stuff happens... ;) . Let&#39;s look at the evolution of degree centrality of a couple of characters like Eddard Stark, Jon Snow, and Tyrion, which showed up in the top 10 of degree centrality in the first book. . %matplotlib inline # Creating a list of degree centrality of all the books evol = [nx.degree_centrality(book) for book in books] # Creating a DataFrame from the list of degree centralities in all the books degree_evol_df = pd.DataFrame.from_records(evol) # Plotting the degree centrality evolution of Eddard-Stark, Tyrion-Lannister and Jon-Snow degree_evol_df[[&#39;Eddard-Stark&#39;, &#39;Tyrion-Lannister&#39;, &#39;Jon-Snow&#39;]].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3e61994c50&gt; . 6. What&#39;s up with Stannis Baratheon? . We can see that the importance of Eddard Stark dies off as the book series progresses. With Jon Snow, there is a drop in the fourth book but a sudden rise in the fifth book. . Now let&#39;s look at various other measures like betweenness centrality and PageRank to find important characters in our Game of Thrones character co-occurrence network and see if we can uncover some more interesting facts about this network. Let&#39;s plot the evolution of betweenness centrality of this network over the five books. We will take the evolution of the top four characters of every book and plot it. . evol = [nx.betweenness_centrality(book, weight=&#39;weight&#39;) for book in books] # Making a DataFrame from the list betweenness_evol_df = pd.DataFrame.from_records(evol).fillna(0) # Finding the top 4 characters in every book set_of_char = set() for i in range(5): set_of_char |= set(list(betweenness_evol_df.T[i].sort_values(ascending=False)[0:4].index)) list_of_char = list(set_of_char) # Plotting the evolution of the top characters betweenness_evol_df[list_of_char].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3e95616278&gt; . 7. What does Google PageRank tell us about GoT? . We see a peculiar rise in the importance of Stannis Baratheon over the books. In the fifth book, he is significantly more important than other characters in the network, even though he is the third most important character according to degree centrality. . PageRank was the initial way Google ranked web pages. It evaluates the inlinks and outlinks of webpages in the world wide web, which is, essentially, a directed network. Let&#39;s look at the importance of characters in the Game of Thrones network according to PageRank. . evol = [nx.pagerank(book, weight=&#39;weight&#39;) for book in books] # Making a DataFrame from the list pagerank_evol_df = pd.DataFrame.from_records(evol).fillna(0) # Finding the top 4 characters in every book set_of_char = set() for i in range(5): set_of_char |= set(list(pagerank_evol_df.T[i].sort_values(ascending=False)[0:4].index)) list_of_char = list(set_of_char) # Plotting the top characters pagerank_evol_df[list_of_char].plot(figsize=(13, 7)) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3e64796b70&gt; . 8. Correlation between different measures . Stannis, Jon Snow, and Daenerys are the most important characters in the fifth book according to PageRank. Eddard Stark follows a similar curve but for degree centrality and betweenness centrality: He is important in the first book but dies into oblivion over the book series. . We have seen three different measures to calculate the importance of a node in a network, and all of them tells us something about the characters and their importance in the co-occurrence network. We see some names pop up in all three measures so maybe there is a strong correlation between them? . Let&#39;s look at the correlation between PageRank, betweenness centrality and degree centrality for the fifth book using Pearson correlation. . # of all the characters in the fifth book. measures = [nx.pagerank(books[4]), nx.betweenness_centrality(books[4], weight=&#39;weight&#39;), nx.degree_centrality(books[4])] # Creating the correlation DataFrame cor = pd.DataFrame.from_records(measures) # Calculating the correlation cor.corr() . Aegon-I-Targaryen Aegon-Targaryen-(son-of-Rhaegar) Aemon-Targaryen-(Maester-Aemon) Aenys-Frey Aeron-Greyjoy Aerys-II-Targaryen Aggo Alliser-Thorne Alys-Karstark Alysane-Mormont ... Wun-Weg-Wun-Dar-Wun Wylis-Manderly Wyman-Manderly Xaro-Xhoan-Daxos Yandry Yellow-Dick Yezzan-zo-Qaggaz Ygritte Ysilla Yurkhaz-zo-Yunzak . Aegon-I-Targaryen 1.000000 | 0.278893 | 0.882815 | 0.999467 | 0.320632 | 0.999048 | 0.971752 | 0.997956 | 0.999952 | 0.998448 | ... | 0.999555 | 0.999994 | -0.008652 | 0.999886 | 0.999258 | 0.995381 | 0.999977 | 0.999249 | 0.938126 | 1.000000 | . Aegon-Targaryen-(son-of-Rhaegar) 0.278893 | 1.000000 | 0.697294 | 0.310094 | 0.999043 | 0.320525 | 0.497653 | 0.216958 | 0.269464 | 0.224971 | ... | 0.307418 | 0.275465 | 0.957873 | 0.264389 | 0.315685 | 0.369802 | 0.285400 | 0.241484 | 0.594191 | 0.278893 | . Aemon-Targaryen-(Maester-Aemon) 0.882815 | 0.697294 | 1.000000 | 0.897679 | 0.727980 | 0.902468 | 0.968733 | 0.850996 | 0.878167 | 0.855281 | ... | 0.896435 | 0.881133 | 0.462065 | 0.875636 | 0.900257 | 0.923834 | 0.885981 | 0.863957 | 0.990853 | 0.882815 | . Aenys-Frey 0.999467 | 0.310094 | 0.897679 | 1.000000 | 0.351383 | 0.999940 | 0.978939 | 0.995338 | 0.999099 | 0.996097 | ... | 0.999996 | 0.999344 | 0.023997 | 0.998862 | 0.999983 | 0.997984 | 0.999665 | 0.997452 | 0.948931 | 0.999467 | . Aeron-Greyjoy 0.320632 | 0.999043 | 0.727980 | 0.351383 | 1.000000 | 0.361652 | 0.535117 | 0.259450 | 0.311330 | 0.267376 | ... | 0.348747 | 0.317250 | 0.944394 | 0.306321 | 0.356887 | 0.410089 | 0.327049 | 0.283700 | 0.628804 | 0.320632 | . Aerys-II-Targaryen 0.999048 | 0.320525 | 0.902468 | 0.999940 | 0.361652 | 1.000000 | 0.981124 | 0.994218 | 0.998572 | 0.995067 | ... | 0.999905 | 0.998886 | 0.034984 | 0.998277 | 0.999987 | 0.998622 | 0.999321 | 0.996608 | 0.952341 | 0.999048 | . Aggo 0.971752 | 0.497653 | 0.968733 | 0.978939 | 0.535117 | 0.981124 | 1.000000 | 0.954686 | 0.969392 | 0.957099 | ... | 0.978361 | 0.970904 | 0.227586 | 0.968085 | 0.980124 | 0.989921 | 0.973331 | 0.961881 | 0.993353 | 0.971752 | . Alliser-Thorne 0.997956 | 0.216958 | 0.850996 | 0.995338 | 0.259450 | 0.994218 | 0.954686 | 1.000000 | 0.998535 | 0.999966 | ... | 0.995606 | 0.998178 | -0.072532 | 0.998806 | 0.994753 | 0.987212 | 0.997500 | 0.999683 | 0.914080 | 0.997956 | . Alys-Karstark 0.999952 | 0.269464 | 0.878167 | 0.999099 | 0.311330 | 0.998572 | 0.969392 | 0.998535 | 1.000000 | 0.998946 | ... | 0.999214 | 0.999981 | -0.018455 | 0.999986 | 0.998832 | 0.994392 | 0.999862 | 0.999581 | 0.934686 | 0.999952 | . Alysane-Mormont 0.998448 | 0.224971 | 0.855281 | 0.996097 | 0.267376 | 0.995067 | 0.957099 | 0.999966 | 0.998946 | 1.000000 | ... | 0.996342 | 0.998640 | -0.064336 | 0.999174 | 0.995560 | 0.988488 | 0.998047 | 0.999856 | 0.917381 | 0.998448 | . Archibald-Yronwood 0.999945 | 0.268800 | 0.877837 | 0.999069 | 0.310674 | 0.998535 | 0.969222 | 0.998572 | 1.000000 | 0.998977 | ... | 0.999187 | 0.999976 | -0.019145 | 0.999990 | 0.998798 | 0.994318 | 0.999851 | 0.999601 | 0.934440 | 0.999945 | . Areo-Hotah 0.999389 | 0.312281 | 0.898690 | 0.999997 | 0.353536 | 0.999962 | 0.979406 | 0.995114 | 0.998999 | 0.995891 | ... | 0.999987 | 0.999258 | 0.026297 | 0.998749 | 0.999994 | 0.998128 | 0.999603 | 0.997286 | 0.949654 | 0.999389 | . Arianne-Martell 0.997788 | 0.342119 | 0.912090 | 0.999426 | 0.382894 | 0.999738 | 0.985292 | 0.991500 | 0.997088 | 0.992536 | ... | 0.999327 | 0.997544 | 0.057846 | 0.996672 | 0.999608 | 0.999561 | 0.998216 | 0.994464 | 0.959073 | 0.997788 | . Arnolf-Karstark 0.152395 | 0.991607 | 0.598771 | 0.184578 | 0.985003 | 0.195370 | 0.381337 | 0.088930 | 0.142698 | 0.097110 | ... | 0.181812 | 0.148868 | 0.986964 | 0.137484 | 0.190360 | 0.246577 | 0.159096 | 0.113997 | 0.485215 | 0.152395 | . Arron 0.999597 | 0.306032 | 0.895789 | 0.999991 | 0.347382 | 0.999884 | 0.978058 | 0.995741 | 0.999271 | 0.996465 | ... | 0.999999 | 0.999490 | 0.019728 | 0.999056 | 0.999948 | 0.997704 | 0.999767 | 0.997748 | 0.947575 | 0.999597 | . Arthor-Karstark 0.997776 | 0.214260 | 0.849541 | 0.995068 | 0.256781 | 0.993918 | 0.953860 | 0.999996 | 0.998382 | 0.999940 | ... | 0.995343 | 0.998007 | -0.075287 | 0.998667 | 0.994467 | 0.986767 | 0.997301 | 0.999609 | 0.912956 | 0.997776 | . Arya-Stark 0.481352 | 0.975994 | 0.836668 | 0.509710 | 0.984587 | 0.519136 | 0.674618 | 0.424358 | 0.472736 | 0.431783 | ... | 0.507288 | 0.478222 | 0.872330 | 0.468088 | 0.514766 | 0.563282 | 0.487287 | 0.447038 | 0.755105 | 0.481352 | . Arys-Oakheart 0.999861 | 0.294844 | 0.890514 | 0.999872 | 0.336359 | 0.999636 | 0.975547 | 0.996754 | 0.999650 | 0.997382 | ... | 0.999913 | 0.999796 | 0.007999 | 0.999497 | 0.999761 | 0.996841 | 0.999951 | 0.998466 | 0.943762 | 0.999861 | . Asha-Greyjoy -0.446205 | 0.734978 | 0.026451 | -0.416752 | 0.704614 | -0.406735 | -0.222395 | -0.502479 | -0.454958 | -0.495359 | ... | -0.419308 | -0.449395 | 0.898758 | -0.459641 | -0.411394 | -0.358224 | -0.440125 | -0.480536 | -0.108687 | -0.446205 | . Ashara-Dayne 0.998672 | 0.229056 | 0.857448 | 0.996459 | 0.271416 | 0.995474 | 0.958306 | 0.999923 | 0.999130 | 0.999991 | ... | 0.996691 | 0.998850 | -0.060148 | 0.999335 | 0.995946 | 0.989114 | 0.998300 | 0.999918 | 0.919043 | 0.998672 | . Axell-Florent -0.506689 | 0.686610 | -0.042352 | -0.478274 | 0.654152 | -0.468592 | -0.288911 | -0.560743 | -0.515117 | -0.553922 | ... | -0.480743 | -0.509761 | 0.866481 | -0.519624 | -0.473097 | -0.421577 | -0.500829 | -0.539704 | -0.176787 | -0.506689 | . Azor-Ahai 1.000000 | 0.278072 | 0.882413 | 0.999439 | 0.319822 | 0.999010 | 0.971550 | 0.998011 | 0.999960 | 0.998495 | ... | 0.999529 | 0.999996 | -0.009507 | 0.999899 | 0.999224 | 0.995298 | 0.999971 | 0.999282 | 0.937830 | 1.000000 | . Balon-Greyjoy 0.381983 | 0.994033 | 0.771322 | 0.411949 | 0.997853 | 0.421940 | 0.589299 | 0.322148 | 0.372904 | 0.329914 | ... | 0.409384 | 0.378683 | 0.920830 | 0.368012 | 0.417305 | 0.468945 | 0.388243 | 0.345897 | 0.678383 | 0.381983 | . Balon-Swann 0.926722 | 0.619294 | 0.994621 | 0.938495 | 0.653045 | 0.942233 | 0.989222 | 0.900818 | 0.922994 | 0.904355 | ... | 0.937520 | 0.925376 | 0.367715 | 0.920954 | 0.940511 | 0.958516 | 0.929250 | 0.911472 | 0.999501 | 0.926722 | . Barbrey-Dustin -0.028012 | 0.952133 | 0.444807 | 0.004635 | 0.937851 | 0.015626 | 0.208689 | -0.091830 | -0.037811 | -0.083646 | ... | 0.001822 | -0.031579 | 0.999813 | -0.043074 | 0.010521 | 0.068087 | -0.021231 | -0.066712 | 0.319879 | -0.028012 | . Barristan-Selmy 0.253308 | 0.999648 | 0.678025 | 0.284754 | 0.997530 | 0.295273 | 0.474458 | 0.190974 | 0.243811 | 0.199032 | ... | 0.282055 | 0.249855 | 0.965158 | 0.238700 | 0.290391 | 0.345014 | 0.259864 | 0.215645 | 0.572635 | 0.253308 | . Barsena 1.000000 | 0.278893 | 0.882815 | 0.999467 | 0.320632 | 0.999048 | 0.971752 | 0.997956 | 0.999952 | 0.998448 | ... | 0.999555 | 0.999994 | -0.008652 | 0.999886 | 0.999258 | 0.995381 | 0.999977 | 0.999249 | 0.938126 | 1.000000 | . Bartimus 0.999126 | 0.238517 | 0.862414 | 0.997230 | 0.280768 | 0.996352 | 0.961041 | 0.999755 | 0.999488 | 0.999903 | ... | 0.997435 | 0.999269 | -0.050433 | 0.999643 | 0.996774 | 0.990499 | 0.998820 | 0.999995 | 0.922835 | 0.999126 | . Belaquo 0.993139 | 0.389280 | 0.931688 | 0.996427 | 0.429199 | 0.997295 | 0.992683 | 0.983637 | 0.991945 | 0.985084 | ... | 0.996186 | 0.992715 | 0.108344 | 0.991264 | 0.996907 | 0.999778 | 0.993909 | 0.987864 | 0.972185 | 0.993139 | . Belwas 0.994771 | 0.375514 | 0.926172 | 0.997575 | 0.415695 | 0.998280 | 0.990774 | 0.986212 | 0.993722 | 0.987538 | ... | 0.997375 | 0.994400 | 0.093522 | 0.993119 | 0.997967 | 0.999981 | 0.995441 | 0.990068 | 0.968588 | 0.994771 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . Tywin-Lannister -0.454044 | 0.728998 | 0.017674 | -0.424716 | 0.698358 | -0.414739 | -0.230945 | -0.510050 | -0.462758 | -0.502966 | ... | -0.427261 | -0.457220 | 0.894874 | -0.467420 | -0.419380 | -0.366406 | -0.447990 | -0.488217 | -0.117410 | -0.454044 | . Ulmer 0.999995 | 0.281800 | 0.884234 | 0.999561 | 0.323499 | 0.999175 | 0.972463 | 0.997758 | 0.999918 | 0.998274 | ... | 0.999641 | 0.999978 | -0.005623 | 0.999836 | 0.999370 | 0.995667 | 0.999993 | 0.999128 | 0.939171 | 0.999995 | . Unella 0.992156 | 0.156657 | 0.817171 | 0.987546 | 0.199709 | 0.985757 | 0.934628 | 0.998116 | 0.993334 | 0.997578 | ... | 0.987985 | 0.992595 | -0.133587 | 0.993927 | 0.986603 | 0.975571 | 0.991285 | 0.996253 | 0.887478 | 0.992156 | . Val 0.392030 | 0.992785 | 0.778211 | 0.421853 | 0.997080 | 0.431793 | 0.598067 | 0.332444 | 0.382992 | 0.340181 | ... | 0.419301 | 0.388745 | 0.916526 | 0.378121 | 0.427183 | 0.478541 | 0.398261 | 0.356100 | 0.686348 | 0.392030 | . Varamyr -0.149098 | 0.908006 | 0.332844 | -0.116738 | 0.888811 | -0.105815 | 0.088478 | -0.211980 | -0.158786 | -0.203944 | ... | -0.119532 | -0.152626 | 0.990075 | -0.163983 | -0.110891 | -0.053476 | -0.142388 | -0.187290 | 0.202550 | -0.149098 | . Varys 0.377108 | 0.994594 | 0.767958 | 0.407143 | 0.998184 | 0.417157 | 0.585034 | 0.317155 | 0.368010 | 0.324936 | ... | 0.404571 | 0.373801 | 0.922872 | 0.363108 | 0.412511 | 0.464285 | 0.383382 | 0.340949 | 0.674502 | 0.377108 | . Victarion-Greyjoy 0.322654 | 0.998947 | 0.729443 | 0.353382 | 0.999998 | 0.363643 | 0.536921 | 0.261513 | 0.313359 | 0.269433 | ... | 0.350748 | 0.319275 | 0.943690 | 0.308353 | 0.358882 | 0.412037 | 0.329067 | 0.285748 | 0.630464 | 0.322654 | . Viserys-Targaryen 0.565611 | 0.949696 | 0.886696 | 0.592231 | 0.962486 | 0.601052 | 0.744259 | 0.511758 | 0.557498 | 0.518799 | ... | 0.589962 | 0.562665 | 0.819748 | 0.553119 | 0.596964 | 0.642173 | 0.571192 | 0.533242 | 0.816194 | 0.565611 | . Waif 0.999395 | 0.245321 | 0.865943 | 0.997727 | 0.287491 | 0.996926 | 0.962956 | 0.999575 | 0.999688 | 0.999781 | ... | 0.997912 | 0.999513 | -0.043428 | 0.999806 | 0.997313 | 0.991439 | 0.999136 | 0.999992 | 0.925513 | 0.999395 | . Walda-Frey-(daughter-of-Merrett) 0.981860 | 0.455916 | 0.955863 | 0.987527 | 0.494411 | 0.989198 | 0.998873 | 0.967738 | 0.979954 | 0.969775 | ... | 0.987080 | 0.981178 | 0.181104 | 0.978891 | 0.988436 | 0.995528 | 0.983124 | 0.973779 | 0.986768 | 0.981860 | . Walder-Frey-(son-of-Jammos) 0.997255 | 0.207021 | 0.845612 | 0.994306 | 0.249617 | 0.993075 | 0.951610 | 0.999948 | 0.997933 | 0.999831 | ... | 0.994602 | 0.997513 | -0.082669 | 0.998258 | 0.993662 | 0.985539 | 0.996730 | 0.999375 | 0.909910 | 0.997255 | . Walder-Frey-(son-of-Merrett) 0.999998 | 0.280636 | 0.883666 | 0.999525 | 0.322351 | 0.999125 | 0.972179 | 0.997839 | 0.999932 | 0.998345 | ... | 0.999607 | 0.999986 | -0.006836 | 0.999857 | 0.999326 | 0.995553 | 0.999988 | 0.999177 | 0.938753 | 0.999998 | . Weeper 0.644369 | 0.914082 | 0.928061 | 0.668990 | 0.930946 | 0.677119 | 0.806642 | 0.594187 | 0.636840 | 0.600775 | ... | 0.666896 | 0.641636 | 0.759111 | 0.632771 | 0.673353 | 0.714810 | 0.649541 | 0.614263 | 0.869316 | 0.644369 | . Wex-Pyke 1.000000 | 0.279155 | 0.882943 | 0.999476 | 0.320891 | 0.999060 | 0.971817 | 0.997939 | 0.999949 | 0.998432 | ... | 0.999563 | 0.999993 | -0.008379 | 0.999882 | 0.999268 | 0.995407 | 0.999979 | 0.999239 | 0.938221 | 1.000000 | . Wick-Whittlestick 0.997391 | 0.347496 | 0.914423 | 0.999216 | 0.388179 | 0.999591 | 0.986255 | 0.990739 | 0.996635 | 0.991821 | ... | 0.999100 | 0.997127 | 0.063563 | 0.996189 | 0.999432 | 0.999714 | 0.997857 | 0.993845 | 0.960679 | 0.997391 | . Widower 0.999793 | 0.298377 | 0.892191 | 0.999924 | 0.339840 | 0.999729 | 0.976354 | 0.996449 | 0.999545 | 0.997107 | ... | 0.999955 | 0.999714 | 0.011698 | 0.999373 | 0.999835 | 0.997128 | 0.999908 | 0.998254 | 0.944978 | 0.999793 | . Willam-Dustin -0.409763 | 0.761718 | 0.066731 | -0.379766 | 0.732649 | -0.369575 | -0.182908 | -0.467215 | -0.418687 | -0.459935 | ... | -0.382367 | -0.413015 | 0.915703 | -0.423464 | -0.374314 | -0.320293 | -0.403566 | -0.444790 | -0.068522 | -0.409763 | . William-Foxglove 1.000000 | 0.278072 | 0.882413 | 0.999439 | 0.319822 | 0.999010 | 0.971550 | 0.998011 | 0.999960 | 0.998495 | ... | 0.999529 | 0.999996 | -0.009507 | 0.999899 | 0.999224 | 0.995298 | 0.999971 | 0.999282 | 0.937830 | 1.000000 | . Willow-Witch-eye 0.999742 | 0.256999 | 0.871913 | 0.998467 | 0.299025 | 0.997798 | 0.966139 | 0.999151 | 0.999917 | 0.999455 | ... | 0.998619 | 0.999817 | -0.031372 | 0.999971 | 0.998124 | 0.992942 | 0.999565 | 0.999872 | 0.930015 | 0.999742 | . Wulfe 0.999190 | 0.240022 | 0.863198 | 0.997344 | 0.282255 | 0.996483 | 0.961468 | 0.999719 | 0.999536 | 0.999880 | ... | 0.997545 | 0.999327 | -0.048885 | 0.999683 | 0.996898 | 0.990711 | 0.998894 | 0.999999 | 0.923431 | 0.999190 | . Wun-Weg-Wun-Dar-Wun 0.999555 | 0.307418 | 0.896435 | 0.999996 | 0.348747 | 0.999905 | 0.978361 | 0.995606 | 0.999214 | 0.996342 | ... | 1.000000 | 0.999442 | 0.021184 | 0.998992 | 0.999962 | 0.997802 | 0.999734 | 0.997649 | 0.948039 | 0.999555 | . Wylis-Manderly 0.999994 | 0.275465 | 0.881133 | 0.999344 | 0.317250 | 0.998886 | 0.970904 | 0.998178 | 0.999981 | 0.998640 | ... | 0.999442 | 1.000000 | -0.012220 | 0.999934 | 0.999114 | 0.995032 | 0.999946 | 0.999381 | 0.936884 | 0.999994 | . Wyman-Manderly -0.008652 | 0.957873 | 0.462065 | 0.023997 | 0.944394 | 0.034984 | 0.227586 | -0.072532 | -0.018455 | -0.064336 | ... | 0.021184 | -0.012220 | 1.000000 | -0.023721 | 0.029881 | 0.087392 | -0.001869 | -0.047380 | 0.338165 | -0.008652 | . Xaro-Xhoan-Daxos 0.999886 | 0.264389 | 0.875636 | 0.998862 | 0.306321 | 0.998277 | 0.968085 | 0.998806 | 0.999986 | 0.999174 | ... | 0.998992 | 0.999934 | -0.023721 | 1.000000 | 0.998563 | 0.993821 | 0.999761 | 0.999720 | 0.932801 | 0.999886 | . Yandry 0.999258 | 0.315685 | 0.900257 | 0.999983 | 0.356887 | 0.999987 | 0.980124 | 0.994753 | 0.998832 | 0.995560 | ... | 0.999962 | 0.999114 | 0.029881 | 0.998563 | 1.000000 | 0.998341 | 0.999496 | 0.997015 | 0.950771 | 0.999258 | . Yellow-Dick 0.995381 | 0.369802 | 0.923834 | 0.997984 | 0.410089 | 0.998622 | 0.989921 | 0.987212 | 0.994392 | 0.988488 | ... | 0.997802 | 0.995032 | 0.087392 | 0.993821 | 0.998341 | 1.000000 | 0.996009 | 0.990915 | 0.967039 | 0.995381 | . Yezzan-zo-Qaggaz 0.999977 | 0.285400 | 0.885981 | 0.999665 | 0.327049 | 0.999321 | 0.973331 | 0.997500 | 0.999862 | 0.998047 | ... | 0.999734 | 0.999946 | -0.001869 | 0.999761 | 0.999496 | 0.996009 | 1.000000 | 0.998964 | 0.940453 | 0.999977 | . Ygritte 0.999249 | 0.241484 | 0.863957 | 0.997452 | 0.283700 | 0.996608 | 0.961881 | 0.999683 | 0.999581 | 0.999856 | ... | 0.997649 | 0.999381 | -0.047380 | 0.999720 | 0.997015 | 0.990915 | 0.998964 | 1.000000 | 0.924008 | 0.999249 | . Ysilla 0.938126 | 0.594191 | 0.990853 | 0.948931 | 0.628804 | 0.952341 | 0.993353 | 0.914080 | 0.934686 | 0.917381 | ... | 0.948039 | 0.936884 | 0.338165 | 0.932801 | 0.950771 | 0.967039 | 0.940453 | 0.924008 | 1.000000 | 0.938126 | . Yurkhaz-zo-Yunzak 1.000000 | 0.278893 | 0.882815 | 0.999467 | 0.320632 | 0.999048 | 0.971752 | 0.997956 | 0.999952 | 0.998448 | ... | 0.999555 | 0.999994 | -0.008652 | 0.999886 | 0.999258 | 0.995381 | 0.999977 | 0.999249 | 0.938126 | 1.000000 | . 317 rows × 317 columns . 9. Conclusion . We see a high correlation between these three measures for our character co-occurrence network. . So we&#39;ve been looking at different ways to find the important characters in the Game of Thrones co-occurrence network. According to degree centrality, Eddard Stark is the most important character initially in the books. But who is/are the most important character(s) in the fifth book according to these three measures? . # according to degree centrality, betweenness centrality and pagerank. p_rank, b_cent, d_cent = cor.idxmax(axis=1) # Printing out the top character accoding to the three measures print(p_rank) print(b_rank) print(d_rank) . Jon-Snow . NameError Traceback (most recent call last) &lt;ipython-input-255-a08ddd23025c&gt; in &lt;module&gt;() 5 # Printing out the top character accoding to the three measures 6 print(p_rank) -&gt; 7 print(b_rank) 8 print(d_rank) NameError: name &#39;b_rank&#39; is not defined .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/python/2020/02/25/A-Network-Analysis-of-Game-of-Thrones.html",
            "relUrl": "/datacamp/projects/python/2020/02/25/A-Network-Analysis-of-Game-of-Thrones.html",
            "date": " • Feb 25, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Introduction to DataCamp Projects (Python)",
            "content": "1. This is a Jupyter notebook! . A Jupyter notebook is a document that contains text cells (what you&#39;re reading right now) and code cells. What is special with a notebook is that it&#39;s interactive: You can change or add code cells, and then run a cell by first selecting it and then clicking the run cell button above ( ▶| Run ) or hitting ctrl + enter. . . The result will be displayed directly in the notebook. You could use a notebook as a simple calculator. For example, it&#39;s estimated that on average 256 children were born every minute in 2016. The code cell below calculates how many children were born on average on a day. . 256 * 60 * 24 # Children × minutes × hours . 368640 . 2. Put any code in code cells . But a code cell can contain much more than a simple one-liner! This is a notebook running python and you can put any python code in a code cell (but notebooks can run other languages too, like R). Below is a code cell where we define a whole new function (greet). To show the output of greet we run it last in the code cell as the last value is always printed out. . def greet(first_name, last_name): greeting = &#39;My name is &#39; + last_name + &#39;, &#39; + first_name + &#39; &#39; + last_name + &#39;!&#39; return greeting # Replace with your first and last name. # That is, unless your name is already James Bond. greet(&#39;Anurag&#39;, &#39;Peddi&#39;) . &#39;My name is Peddi, Anurag Peddi!&#39; . 3. Jupyter notebooks &#9825; data . We&#39;ve seen that notebooks can display basic objects such as numbers and strings. But notebooks also support the objects used in data science, which makes them great for interactive data analysis! . For example, below we create a pandas DataFrame by reading in a csv-file with the average global temperature for the years 1850 to 2016. If we look at the head of this DataFrame the notebook will render it as a nice-looking table. . import pandas as pd # Reading in the global temperature data global_temp = pd.read_csv(&#39;datasets/global_temperature.csv&#39;) # Take a look at the first datapoints # ... YOUR CODE FOR TASK 3 ... print(global_temp.head()) . year degrees_celsius 0 1850 7.74 1 1851 8.09 2 1852 7.97 3 1853 7.93 4 1854 8.19 . 4. Jupyter notebooks &#9825; plots . Tables are nice but — as the saying goes — &quot;a plot can show a thousand data points&quot;. Notebooks handle plots as well, but it requires a bit of magic. Here magic does not refer to any arcane rituals but to so-called &quot;magic commands&quot; that affect how the Jupyter notebook works. Magic commands start with either % or %% and the command we need to nicely display plots inline is %matplotlib inline. With this magic in place, all plots created in code cells will automatically be displayed inline. . Let&#39;s take a look at the global temperature for the last 150 years. . %matplotlib inline import matplotlib.pyplot as plt # Plotting global temperature in degrees celsius by year plt.plot(global_temp[&#39;year&#39;], global_temp[&#39;degrees_celsius&#39;]) # Adding some nice labels plt.xlabel(&#39;Year&#39;) plt.ylabel(&#39;Degree Celsius&#39;) . &lt;matplotlib.text.Text at 0x7fc6bdfd1d30&gt; . 5. Jupyter notebooks &#9825; a lot more . Tables and plots are the most common outputs when doing data analysis, but Jupyter notebooks can render many more types of outputs such as sound, animation, video, etc. Yes, almost anything that can be shown in a modern web browser. This also makes it possible to include interactive widgets directly in the notebook! . For example, this (slightly complicated) code will create an interactive map showing the locations of the three largest smartphone companies in 2016. You can move and zoom the map, and you can click the markers for more info! . import folium phone_map = folium.Map() # Top three smart phone companies by market share in 2016 companies = [ {&#39;loc&#39;: [37.4970, 127.0266], &#39;label&#39;: &#39;Samsung: ...%&#39;}, {&#39;loc&#39;: [37.3318, -122.0311], &#39;label&#39;: &#39;Apple: ...%&#39;}, {&#39;loc&#39;: [22.5431, 114.0579], &#39;label&#39;: &#39;Huawei: ...%&#39;}] # Adding markers to the map for company in companies: marker = folium.Marker(location=company[&#39;loc&#39;], popup=company[&#39;label&#39;]) marker.add_to(phone_map) # The last object in the cell always gets shown in the notebook phone_map . 6. Goodbye for now! . This was just a short introduction to Jupyter notebooks, an open source technology that is increasingly used for data science and analysis. I hope you enjoyed it! :) . I_am_ready = False # Ps. # Feel free to try out any other stuff in this notebook. # It&#39;s all yours! .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/python/2020/01/29/Introduction-to-DataCamp-Projects.html",
            "relUrl": "/datacamp/projects/python/2020/01/29/Introduction-to-DataCamp-Projects.html",
            "date": " • Jan 29, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Introduction to DataCamp Projects(SQL)",
            "content": "1. This is a Jupyter Notebook! . A Jupyter Notebook is a document that contains text cells (what you&#39;re reading right now) and code cells. What is special with a notebook is that it&#39;s interactive: You can change or add code cells, and then run a cell by first selecting it and then clicking the run cell button above ( ▶| Run ) or hitting Ctrl + Enter. . . The result will be displayed directly in the notebook. You could use a notebook as a simple calculator. For example, it&#39;s estimated that on average 256 children were born every minute in 2016. The code cell below calculates how many children were born on average on a day. . 256 * 60 * 24 # Children × minutes × hours . 368640 . 2. Put any code in code cells . But a code cell can contain much more than a simple one-liner! This is a notebook running Python and you can put any Python code in a code cell (but notebooks can run other languages too, like R). Below is a code cell where we define a whole new function (greet). To show the output of greet we run it last in the code cell as the last value is always printed out. . def greet(first_name, last_name): greeting = &#39;My name is &#39; + last_name + &#39;, &#39; + first_name + &#39; &#39; + last_name + &#39;!&#39; return greeting # Replace with your first and last name. # That is, unless your name is already Jane Bond. greet(&#39;Anurag&#39;, &#39;Peddi&#39;) . &#39;My name is Peddi, Anurag Peddi!&#39; . 3. Jupyter Notebooks &#9825; SQL (part i) . We&#39;ve seen that notebooks can display basic objects such as numbers and strings. But notebooks also support and display the outputs of SQL commands! Using an open source Jupyter extension called ipython-sql, we can connect to a database and issue SQL commands within our notebook. For example, we can connect to a PostgreSQL database that has a table that contains country data, then inspect the first three rows of the table by putting %%sql ahead of the SQL commands (more on the meaning of %% later). . %%sql postgresql:///countries SELECT * FROM countries LIMIT 3; . 3 rows affected. . code name continent region surface_area indep_year local_name gov_form capital cap_long cap_lat . AFG | Afghanistan | Asia | Southern and Central Asia | 652090.0 | 1919 | Afganistan/Afqanestan | Islamic Emirate | Kabul | 69.1761 | 34.5228 | . NLD | Netherlands | Europe | Western Europe | 41526.0 | 1581 | Nederland | Constitutional Monarchy | Amsterdam | 4.89095 | 52.3738 | . ALB | Albania | Europe | Southern Europe | 28748.0 | 1912 | Shqiperia | Republic | Tirane | 19.8172 | 41.3317 | . 4. Jupyter Notebooks &#9825; SQL (part ii) . And after the first connection to the database, the connection code (postgresql:///countries) can be omitted. Let&#39;s do a different query this time and select the row in the countries table for Belgium. Note the single % this time. Again, more on that later. . %sql SELECT * FROM countries where name = &#39;Belgium&#39;; . * postgresql:///countries 1 rows affected. . code name continent region surface_area indep_year local_name gov_form capital cap_long cap_lat . BEL | Belgium | Europe | Western Europe | 30518.0 | 1830 | Belgie/Belgique | Constitutional Monarchy, Federation | Brussels | 4.36761 | 50.8371 | . 5. Jupyter Notebooks &#9825; SQL (part iii) . We can even convert our SQL results to a pandas DataFrame! Let&#39;s convert the entire countries table. . result = %sql SELECT * FROM countries; # To pandas DataFrame df = result.DataFrame() df.info() . * postgresql:///countries 206 rows affected. &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 206 entries, 0 to 205 Data columns (total 11 columns): code 206 non-null object name 206 non-null object continent 206 non-null object region 206 non-null object surface_area 206 non-null float64 indep_year 188 non-null float64 local_name 206 non-null object gov_form 206 non-null object capital 201 non-null object cap_long 204 non-null float64 cap_lat 204 non-null float64 dtypes: float64(4), object(7) memory usage: 17.8+ KB . 6. Jupyter Notebooks &#9825; SQLAlchemy . If SQLAlchemy is your thing, you can do that in this notebook, too! Jupyter Notebooks love everything, apparently... . What&#39;s SQLAlchemy, you ask? SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL. Next, we&#39;ll run the last query we just ran except after connecting to and querying the database using SQLAlchemy. . from sqlalchemy import create_engine engine = create_engine(&quot;postgresql:///countries&quot;); # Query database result = engine.execute(&quot;SELECT * FROM countries;&quot;) # Display column names result.keys() . [&#39;code&#39;, &#39;name&#39;, &#39;continent&#39;, &#39;region&#39;, &#39;surface_area&#39;, &#39;indep_year&#39;, &#39;local_name&#39;, &#39;gov_form&#39;, &#39;capital&#39;, &#39;cap_long&#39;, &#39;cap_lat&#39;] . 7. Jupyter Notebooks &#9825; plots . Tables are nice but — as the saying goes — &quot;a plot can show a thousand data points.&quot; Notebooks handle plots as well, but it requires some more magic. Here magic does not refer to any arcane rituals but to so-called &quot;magic commands&quot; that affect how the Jupyter Notebook works. Magic commands start with either % or %% (just like we saw with %sql and %%sql) and the command we need to nicely display plots inline is %matplotlib inline. With this magic in place, all plots created in code cells will automatically be displayed inline. . Using the previously created pandas DataFrame that we named df, let&#39;s plot the number of countries in each continent as a bar chart using the plot() method of pandas DataFrames. . Now, for the difference between %%sql and %sql: ordinary assignment works for single-line %sql queries while %%sql is for multi-line queries. See the Assignment ipython-sql documentation section for more info. . %matplotlib inline # Plotting number of countries in each continent df.continent.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff916880668&gt; . 8. Goodbye for now! . Tables and plots are the most common outputs when doing data analysis, but Jupyter Notebooks can render many more types of outputs such as sound, animation, video, etc. Yes, almost anything that can be shown in a modern web browser. This also makes it possible to include interactive widgets directly in the notebook! Everything in this collection of Jupyter Widgets can be displayed in this notebook. . But that&#39;s enough for now! This was just a short introduction to Jupyter Notebooks, an open source technology that is increasingly used for data science and analysis. We hope you enjoyed it! :) . I_am_ready = True # P.S. Feel free to try out any other stuff in this notebook. # It&#39;s all yours! .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/sql/2020/01/25/Introduction-to-DataCamp-Projects.html",
            "relUrl": "/datacamp/projects/sql/2020/01/25/Introduction-to-DataCamp-Projects.html",
            "date": " • Jan 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://anuraganalog.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://anuraganalog.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}