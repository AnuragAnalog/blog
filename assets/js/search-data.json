{
  
    
        "post0": {
            "title": "Tabular Playground Series Mar 2022",
            "content": "!pip3 install kaggle !pip3 install prophet !pip3 install pystan==2.19.1.1 . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: prophet in /usr/local/lib/python3.7/dist-packages (1.0.1) Requirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.19.1.1) Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.21.5) Requirement already satisfied: holidays&gt;=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.10.5.2) Requirement already satisfied: pandas&gt;=1.0.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.3.5) Requirement already satisfied: convertdate&gt;=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.4.0) Requirement already satisfied: python-dateutil&gt;=2.8.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.8.2) Requirement already satisfied: tqdm&gt;=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (4.63.0) Requirement already satisfied: matplotlib&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (3.2.2) Requirement already satisfied: cmdstanpy==0.9.68 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.9.68) Requirement already satisfied: setuptools-git&gt;=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.2) Requirement already satisfied: LunarCalendar&gt;=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.0.9) Requirement already satisfied: Cython&gt;=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.29.28) Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from cmdstanpy==0.9.68-&gt;prophet) (5.1.0) Requirement already satisfied: pymeeus&lt;=1,&gt;=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate&gt;=2.1.2-&gt;prophet) (0.5.11) Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays&gt;=0.10.2-&gt;prophet) (0.2.1) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays&gt;=0.10.2-&gt;prophet) (1.15.0) Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays&gt;=0.10.2-&gt;prophet) (2.2.3) Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from LunarCalendar&gt;=0.0.9-&gt;prophet) (2018.9) Requirement already satisfied: ephem&gt;=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar&gt;=0.0.9-&gt;prophet) (4.1.3) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (1.4.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (3.0.7) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (0.11.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=2.0.0-&gt;prophet) (3.10.0.2) Requirement already satisfied: pystan==2.19.1.1 in /usr/local/lib/python3.7/dist-packages (2.19.1.1) Requirement already satisfied: Cython!=0.25.1,&gt;=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (0.29.28) Requirement already satisfied: numpy&gt;=1.7 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (1.21.5) . import tqdm import numpy as np import pandas as pd import seaborn as sns from zipfile import ZipFile from prophet import Prophet from matplotlib import pyplot as plt . %matplotlib inline plt.rcParams[&#39;figure.figsize&#39;] = (12, 12) . Before running the below cell, upload your kaggle token, to make sure an error doesn&#39;t popup. . !mkdir ~/.kaggle !cp kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . mkdir: cannot create directory ‘/root/.kaggle’: File exists . !kaggle competitions download -c tabular-playground-series-mar-2022 . tabular-playground-series-mar-2022.zip: Skipping, found more recently modified local copy (use --force to force download) . with ZipFile(&#39;/content/tabular-playground-series-mar-2022.zip&#39;, &#39;r&#39;) as zf: zf.extractall(&#39;./&#39;) . Loading the data . train = pd.read_csv(&#39;train.csv&#39;, index_col=&#39;row_id&#39;, parse_dates=[&#39;time&#39;]) train.head() . time x y direction congestion . row_id . 0 1991-04-01 | 0 | 0 | EB | 70 | . 1 1991-04-01 | 0 | 0 | NB | 49 | . 2 1991-04-01 | 0 | 0 | SB | 24 | . 3 1991-04-01 | 0 | 1 | EB | 18 | . 4 1991-04-01 | 0 | 1 | NB | 60 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train.info() train.describe() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 848835 entries, 0 to 848834 Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 time 848835 non-null datetime64[ns] 1 x 848835 non-null int64 2 y 848835 non-null int64 3 direction 848835 non-null object 4 congestion 848835 non-null int64 dtypes: datetime64[ns](1), int64(3), object(1) memory usage: 38.9+ MB . x y congestion . count 848835.000000 | 848835.000000 | 848835.000000 | . mean 1.138462 | 1.630769 | 47.815305 | . std 0.801478 | 1.089379 | 16.799392 | . min 0.000000 | 0.000000 | 0.000000 | . 25% 0.000000 | 1.000000 | 35.000000 | . 50% 1.000000 | 2.000000 | 47.000000 | . 75% 2.000000 | 3.000000 | 60.000000 | . max 2.000000 | 3.000000 | 100.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; sns.heatmap(train.corr(), annot=True, vmin=-1, vmax=1, cmap=&#39;RdYlGn&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fa74ad97410&gt; . test = pd.read_csv(&#39;test.csv&#39;, index_col=&#39;row_id&#39;, parse_dates=[&#39;time&#39;]) test.head() . time x y direction . row_id . 848835 1991-09-30 12:00:00 | 0 | 0 | EB | . 848836 1991-09-30 12:00:00 | 0 | 0 | NB | . 848837 1991-09-30 12:00:00 | 0 | 0 | SB | . 848838 1991-09-30 12:00:00 | 0 | 1 | EB | . 848839 1991-09-30 12:00:00 | 0 | 1 | NB | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; There are no missing values, in the data. . if train.isna().any().any(): print(train.isna().sum()/train.shape[0]) else: print(&quot;No Missing values&quot;) . No Missing values . Preparation . test[&#39;congestion&#39;] = 0.0 . grouped_train_data = train.groupby([&#39;time&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;]) grouped_test_data = test.groupby([&#39;time&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;]) . train_dict = dict() test_dict = dict() for g in grouped_train_data: if (g[0][1], g[0][2], g[0][3]) in train_dict.keys(): train_dict[(g[0][1], g[0][2], g[0][3])].append((g[0][0], g[1][&#39;congestion&#39;].values[0])) else: train_dict[(g[0][1], g[0][2], g[0][3])] = [(g[0][0], g[1][&#39;congestion&#39;].values[0])] for g in grouped_test_data: if (g[0][1], g[0][2], g[0][3]) in test_dict.keys(): test_dict[(g[0][1], g[0][2], g[0][3])].append((g[0][0], g[1][&#39;congestion&#39;].values[0])) else: test_dict[(g[0][1], g[0][2], g[0][3])] = [(g[0][0], g[1][&#39;congestion&#39;].values[0])] . for idx, li in train_dict.items(): train_dict[idx] = pd.DataFrame(columns=[&#39;ds&#39;, &#39;y&#39;], data=li) for idx, li in test_dict.items(): test_dict[idx] = pd.DataFrame(columns=[&#39;ds&#39;, &#39;y&#39;], data=li).drop([&#39;y&#39;], axis=1) . Modelling . Approach-1 . In this method, I have grouped the data into a number of instances and made the predictions on that instances. . An instance is uniquely identifiable by its a key which is a combination of its cordinates and the direction. . for idx, train_data in tqdm.tqdm(train_dict.items()): model = Prophet() model.fit(train_data) forecast = model.predict(test_dict[idx]) test_dict[idx][&#39;congestion&#39;] = np.round(forecast[&#39;yhat&#39;]) test_dict[idx][&#39;x&#39;] = idx[0] test_dict[idx][&#39;y&#39;] = idx[1] test_dict[idx][&#39;direction&#39;] = idx[2] . 0%| | 0/65 [00:00&lt;?, ?it/s]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 2%|▏ | 1/65 [00:08&lt;08:55, 8.36s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 3%|▎ | 2/65 [00:12&lt;06:23, 6.09s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 5%|▍ | 3/65 [00:20&lt;06:55, 6.70s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 6%|▌ | 4/65 [00:29&lt;07:53, 7.76s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 8%|▊ | 5/65 [00:36&lt;07:21, 7.37s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 9%|▉ | 6/65 [00:41&lt;06:39, 6.77s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 11%|█ | 7/65 [00:48&lt;06:37, 6.85s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 12%|█▏ | 8/65 [00:55&lt;06:24, 6.75s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 14%|█▍ | 9/65 [01:00&lt;05:49, 6.24s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 15%|█▌ | 10/65 [01:06&lt;05:35, 6.10s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 17%|█▋ | 11/65 [01:11&lt;05:08, 5.71s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 18%|█▊ | 12/65 [01:16&lt;04:56, 5.60s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 20%|██ | 13/65 [01:24&lt;05:25, 6.25s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 22%|██▏ | 14/65 [01:28&lt;04:46, 5.63s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 23%|██▎ | 15/65 [01:34&lt;04:46, 5.72s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 25%|██▍ | 16/65 [01:39&lt;04:31, 5.55s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 26%|██▌ | 17/65 [01:45&lt;04:26, 5.55s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 28%|██▊ | 18/65 [01:51&lt;04:29, 5.74s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 29%|██▉ | 19/65 [01:57&lt;04:23, 5.72s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 31%|███ | 20/65 [02:02&lt;04:14, 5.65s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 32%|███▏ | 21/65 [02:06&lt;03:41, 5.03s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 34%|███▍ | 22/65 [02:11&lt;03:46, 5.26s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 35%|███▌ | 23/65 [02:18&lt;03:52, 5.54s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 37%|███▋ | 24/65 [02:21&lt;03:24, 4.99s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 38%|███▊ | 25/65 [02:28&lt;03:43, 5.58s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 40%|████ | 26/65 [02:37&lt;04:09, 6.40s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 42%|████▏ | 27/65 [02:44&lt;04:15, 6.72s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 43%|████▎ | 28/65 [02:51&lt;04:10, 6.78s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 45%|████▍ | 29/65 [02:56&lt;03:44, 6.24s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 46%|████▌ | 30/65 [03:02&lt;03:34, 6.14s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 48%|████▊ | 31/65 [03:08&lt;03:34, 6.29s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 49%|████▉ | 32/65 [03:14&lt;03:17, 5.99s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 51%|█████ | 33/65 [03:19&lt;03:07, 5.85s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 52%|█████▏ | 34/65 [03:23&lt;02:43, 5.28s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 54%|█████▍ | 35/65 [03:29&lt;02:39, 5.33s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 55%|█████▌ | 36/65 [03:35&lt;02:47, 5.76s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 57%|█████▋ | 37/65 [03:41&lt;02:41, 5.77s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 58%|█████▊ | 38/65 [03:46&lt;02:30, 5.57s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 60%|██████ | 39/65 [03:49&lt;02:04, 4.78s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 62%|██████▏ | 40/65 [03:55&lt;02:07, 5.12s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 63%|██████▎ | 41/65 [04:03&lt;02:24, 6.03s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 65%|██████▍ | 42/65 [04:10&lt;02:20, 6.10s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 66%|██████▌ | 43/65 [04:14&lt;02:03, 5.62s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 68%|██████▊ | 44/65 [04:21&lt;02:06, 6.01s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 69%|██████▉ | 45/65 [04:27&lt;02:01, 6.08s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 71%|███████ | 46/65 [04:32&lt;01:48, 5.70s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 72%|███████▏ | 47/65 [04:37&lt;01:39, 5.54s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 74%|███████▍ | 48/65 [04:42&lt;01:29, 5.29s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 75%|███████▌ | 49/65 [04:49&lt;01:34, 5.92s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 77%|███████▋ | 50/65 [04:55&lt;01:25, 5.69s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 78%|███████▊ | 51/65 [05:00&lt;01:17, 5.51s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 80%|████████ | 52/65 [05:04&lt;01:07, 5.20s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 82%|████████▏ | 53/65 [05:11&lt;01:08, 5.74s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 83%|████████▎ | 54/65 [05:17&lt;01:05, 5.93s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 85%|████████▍ | 55/65 [05:23&lt;00:57, 5.77s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 86%|████████▌ | 56/65 [05:28&lt;00:51, 5.73s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 88%|████████▊ | 57/65 [05:35&lt;00:48, 6.03s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 89%|████████▉ | 58/65 [05:40&lt;00:40, 5.78s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 91%|█████████ | 59/65 [05:46&lt;00:33, 5.58s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 92%|█████████▏| 60/65 [05:51&lt;00:28, 5.67s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 94%|█████████▍| 61/65 [05:55&lt;00:20, 5.05s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 95%|█████████▌| 62/65 [05:59&lt;00:14, 4.68s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 97%|█████████▋| 63/65 [06:04&lt;00:09, 4.79s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 98%|█████████▊| 64/65 [06:08&lt;00:04, 4.56s/it]INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this. 100%|██████████| 65/65 [06:11&lt;00:00, 5.72s/it] . preds_semi_final = pd.concat(test_dict.values(), ignore_index=True) preds_final = test.reset_index().merge(preds_semi_final, left_on=[&#39;time&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;], right_on=[&#39;ds&#39;, &#39;x&#39;, &#39;y&#39;, &#39;direction&#39;])[[&#39;row_id&#39;, &#39;congestion_y&#39;]] . submission = pd.read_csv(&#39;/content/sample_submission.csv&#39;) submission = submission.merge(preds_final, on=&#39;row_id&#39;)[[&#39;row_id&#39;, &#39;congestion_y&#39;]].rename(columns={&#39;congestion_y&#39;: &#39;congestion&#39;}) submission.to_csv(&#39;output.csv&#39;, index=False) . !kaggle competitions submit -c tabular-playground-series-mar-2022 -f output.csv -m &quot;FB Prophet correct 2 with round&quot; . 100% 27.4k/27.4k [00:00&lt;00:00, 150kB/s] Successfully submitted to Tabular Playground Series - Mar 2022 .",
            "url": "https://anuraganalog.github.io/blog/kaggle/fbprophet/jupyter/tps/2022/03/24/Tabular-Playground-Series-Mar-2022-FB-Prophet.html",
            "relUrl": "/kaggle/fbprophet/jupyter/tps/2022/03/24/Tabular-Playground-Series-Mar-2022-FB-Prophet.html",
            "date": " • Mar 24, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Visualizing-COVID-19",
            "content": "1. From epidemic to pandemic . In December 2019, COVID-19 coronavirus was first identified in the Wuhan region of China. By March 11, 2020, the World Health Organization (WHO) categorized the COVID-19 outbreak as a pandemic. A lot has happened in the months in between with major outbreaks in Iran, South Korea, and Italy. . We know that COVID-19 spreads through respiratory droplets, such as through coughing, sneezing, or speaking. But, how quickly did the virus spread across the globe? And, can we see any effect from country-wide policies, like shutdowns and quarantines? . Fortunately, organizations around the world have been collecting data so that governments can monitor and learn from this pandemic. Notably, the Johns Hopkins University Center for Systems Science and Engineering created a publicly available data repository to consolidate this data from sources like the WHO, the Centers for Disease Control and Prevention (CDC), and the Ministry of Health from multiple countries. . In this notebook, you will visualize COVID-19 data from the first several weeks of the outbreak to see at what point this virus became a global pandemic. . Please note that information and data regarding COVID-19 is frequently being updated. The data used in this project was pulled on March 17, 2020, and should not be considered to be the most up to date data available. . library(readr) library(ggplot2) library(dplyr) # Read datasets/confirmed_cases_worldwide.csv into confirmed_cases_worldwide confirmed_cases_worldwide &lt;- read_csv(&#39;datasets/confirmed_cases_worldwide.csv&#39;) # See the result confirmed_cases_worldwide . Parsed with column specification: cols( date = col_date(format = &#34;&#34;), cum_cases = col_double() ) . A spec_tbl_df: 56 x 2 datecum_cases . &lt;date&gt;&lt;dbl&gt; . 2020-01-22 | 555 | . 2020-01-23 | 653 | . 2020-01-24 | 941 | . 2020-01-25 | 1434 | . 2020-01-26 | 2118 | . 2020-01-27 | 2927 | . 2020-01-28 | 5578 | . 2020-01-29 | 6166 | . 2020-01-30 | 8234 | . 2020-01-31 | 9927 | . 2020-02-01 | 12038 | . 2020-02-02 | 16787 | . 2020-02-03 | 19881 | . 2020-02-04 | 23892 | . 2020-02-05 | 27635 | . 2020-02-06 | 30817 | . 2020-02-07 | 34391 | . 2020-02-08 | 37120 | . 2020-02-09 | 40150 | . 2020-02-10 | 42762 | . 2020-02-11 | 44802 | . 2020-02-12 | 45221 | . 2020-02-13 | 60368 | . 2020-02-14 | 66885 | . 2020-02-15 | 69030 | . 2020-02-16 | 71224 | . 2020-02-17 | 73258 | . 2020-02-18 | 75136 | . 2020-02-19 | 75639 | . 2020-02-20 | 76197 | . 2020-02-21 | 76823 | . 2020-02-22 | 78579 | . 2020-02-23 | 78965 | . 2020-02-24 | 79568 | . 2020-02-25 | 80413 | . 2020-02-26 | 81395 | . 2020-02-27 | 82754 | . 2020-02-28 | 84120 | . 2020-02-29 | 86011 | . 2020-03-01 | 88369 | . 2020-03-02 | 90306 | . 2020-03-03 | 92840 | . 2020-03-04 | 95120 | . 2020-03-05 | 97882 | . 2020-03-06 | 101784 | . 2020-03-07 | 105821 | . 2020-03-08 | 109795 | . 2020-03-09 | 113561 | . 2020-03-10 | 118592 | . 2020-03-11 | 125865 | . 2020-03-12 | 128343 | . 2020-03-13 | 145193 | . 2020-03-14 | 156097 | . 2020-03-15 | 167449 | . 2020-03-16 | 181531 | . 2020-03-17 | 197146 | . 2. Confirmed cases throughout the world . The table above shows the cumulative confirmed cases of COVID-19 worldwide by date. Just reading numbers in a table makes it hard to get a sense of the scale and growth of the outbreak. Let&#39;s draw a line plot to visualize the confirmed cases worldwide. . # Label the y-axis ggplot(data=confirmed_cases_worldwide, aes(x=date, y=cum_cases)) + geom_line() + geom_point() + ylab(&quot;Cumulative confirmed cases&quot;) . 3. China compared to the rest of the world . The y-axis in that plot is pretty scary, with the total number of confirmed cases around the world approaching 200,000. Beyond that, some weird things are happening: there is an odd jump in mid February, then the rate of new cases slows down for a while, then speeds up again in March. We need to dig deeper to see what is happening. . Early on in the outbreak, the COVID-19 cases were primarily centered in China. Let&#39;s plot confirmed COVID-19 cases in China and the rest of the world separately to see if it gives us any insight. . We&#39;ll build on this plot in future tasks. One thing that will be important for the following tasks is that you add aesthetics within the line geometry of your ggplot, rather than making them global aesthetics. . confirmed_cases_china_vs_world &lt;- read_csv(&#39;datasets/confirmed_cases_china_vs_world.csv&#39;) # See the result confirmed_cases_china_vs_world # Draw a line plot of cumulative cases vs. date, grouped and colored by is_china # Define aesthetics within the line geom plt_cum_confirmed_cases_china_vs_world &lt;- ggplot(data=confirmed_cases_china_vs_world) + geom_line(aes(x=date, y=cum_cases, group=is_china, color=is_china)) + ylab(&quot;Cumulative confirmed cases&quot;) # See the plot plt_cum_confirmed_cases_china_vs_world . Parsed with column specification: cols( is_china = col_character(), date = col_date(format = &#34;&#34;), cases = col_double(), cum_cases = col_double() ) . A spec_tbl_df: 112 x 4 is_chinadatecasescum_cases . &lt;chr&gt;&lt;date&gt;&lt;dbl&gt;&lt;dbl&gt; . China | 2020-01-22 | 548 | 548 | . China | 2020-01-23 | 95 | 643 | . China | 2020-01-24 | 277 | 920 | . China | 2020-01-25 | 486 | 1406 | . China | 2020-01-26 | 669 | 2075 | . China | 2020-01-27 | 802 | 2877 | . China | 2020-01-28 | 2632 | 5509 | . China | 2020-01-29 | 578 | 6087 | . China | 2020-01-30 | 2054 | 8141 | . China | 2020-01-31 | 1661 | 9802 | . China | 2020-02-01 | 2089 | 11891 | . China | 2020-02-02 | 4739 | 16630 | . China | 2020-02-03 | 3086 | 19716 | . China | 2020-02-04 | 3991 | 23707 | . China | 2020-02-05 | 3733 | 27440 | . China | 2020-02-06 | 3147 | 30587 | . China | 2020-02-07 | 3523 | 34110 | . China | 2020-02-08 | 2704 | 36814 | . China | 2020-02-09 | 3015 | 39829 | . China | 2020-02-10 | 2525 | 42354 | . China | 2020-02-11 | 2032 | 44386 | . China | 2020-02-12 | 373 | 44759 | . China | 2020-02-13 | 15136 | 59895 | . China | 2020-02-14 | 6463 | 66358 | . China | 2020-02-15 | 2055 | 68413 | . China | 2020-02-16 | 2100 | 70513 | . China | 2020-02-17 | 1921 | 72434 | . China | 2020-02-18 | 1777 | 74211 | . China | 2020-02-19 | 408 | 74619 | . China | 2020-02-20 | 458 | 75077 | . ... | ... | ... | ... | . Not China | 2020-02-17 | 113 | 824 | . Not China | 2020-02-18 | 101 | 925 | . Not China | 2020-02-19 | 95 | 1020 | . Not China | 2020-02-20 | 100 | 1120 | . Not China | 2020-02-21 | 153 | 1273 | . Not China | 2020-02-22 | 305 | 1578 | . Not China | 2020-02-23 | 365 | 1943 | . Not China | 2020-02-24 | 384 | 2327 | . Not China | 2020-02-25 | 332 | 2659 | . Not China | 2020-02-26 | 570 | 3229 | . Not China | 2020-02-27 | 925 | 4154 | . Not China | 2020-02-28 | 1038 | 5192 | . Not China | 2020-02-29 | 1463 | 6655 | . Not China | 2020-03-01 | 1782 | 8437 | . Not China | 2020-03-02 | 1733 | 10170 | . Not China | 2020-03-03 | 2409 | 12579 | . Not China | 2020-03-04 | 2155 | 14734 | . Not China | 2020-03-05 | 2611 | 17345 | . Not China | 2020-03-06 | 3749 | 21094 | . Not China | 2020-03-07 | 3957 | 25051 | . Not China | 2020-03-08 | 3921 | 28972 | . Not China | 2020-03-09 | 3729 | 32701 | . Not China | 2020-03-10 | 5004 | 37705 | . Not China | 2020-03-11 | 7239 | 44944 | . Not China | 2020-03-12 | 2467 | 47411 | . Not China | 2020-03-13 | 16837 | 64248 | . Not China | 2020-03-14 | 10872 | 75120 | . Not China | 2020-03-15 | 11326 | 86446 | . Not China | 2020-03-16 | 14052 | 100498 | . Not China | 2020-03-17 | 15590 | 116088 | . 4. Let&#39;s annotate! . Wow! The two lines have very different shapes. In February, the majority of cases were in China. That changed in March when it really became a global outbreak: around March 14, the total number of cases outside China overtook the cases inside China. This was days after the WHO declared a pandemic. . There were a couple of other landmark events that happened during the outbreak. For example, the huge jump in the China line on February 13, 2020 wasn&#39;t just a bad day regarding the outbreak; China changed the way it reported figures on that day (CT scans were accepted as evidence for COVID-19, rather than only lab tests). . By annotating events like this, we can better interpret changes in the plot. . who_events &lt;- tribble( ~ date, ~ event, &quot;2020-01-30&quot;, &quot;Global health nemergency declared&quot;, &quot;2020-03-11&quot;, &quot;Pandemic ndeclared&quot;, &quot;2020-02-13&quot;, &quot;China reporting nchange&quot; ) %&gt;% mutate(date = as.Date(date)) # Using who_events, add vertical dashed lines with an xintercept at date # and text at date, labeled by event, and at 100000 on the y-axis plt_cum_confirmed_cases_china_vs_world + geom_vline(data=who_events, linetype=&#39;dashed&#39;, aes(xintercept=date)) + geom_text(data=who_events, y=1e+05, aes(x=date, label=event)) . 5. Adding a trend line to China . When trying to assess how big future problems are going to be, we need a measure of how fast the number of cases is growing. A good starting point is to see if the cases are growing faster or slower than linearly. . There is a clear surge of cases around February 13, 2020, with the reporting change in China. However, a couple of days after, the growth of cases in China slows down. How can we describe COVID-19&#39;s growth in China after February 15, 2020? . china_after_feb15 &lt;- filter(confirmed_cases_china_vs_world, date &gt;= &quot;2020-02-15&quot; &amp; is_china == &#39;China&#39;) # Using china_after_feb15, draw a line plot cum_cases vs. date # Add a smooth trend line using linear regression, no error bars ggplot(data=china_after_feb15, aes(x=date, y=cum_cases)) + geom_line() + geom_smooth(method=&#39;lm&#39;, se=FALSE) + ylab(&quot;Cumulative confirmed cases&quot;) . `geom_smooth()` using formula &#39;y ~ x&#39; . 6. And the rest of the world? . From the plot above, the growth rate in China is slower than linear. That&#39;s great news because it indicates China has at least somewhat contained the virus in late February and early March. . How does the rest of the world compare to linear growth? . not_china &lt;- filter(confirmed_cases_china_vs_world, is_china != &#39;China&#39;) # Using not_china, draw a line plot cum_cases vs. date # Add a smooth trend line using linear regression, no error bars plt_not_china_trend_lin &lt;- ggplot(data=not_china, aes(x=date, y=cum_cases)) + geom_line() + geom_smooth(method=&#39;lm&#39;, se=FALSE) + ylab(&quot;Cumulative confirmed cases&quot;) # See the result plt_not_china_trend_lin . `geom_smooth()` using formula &#39;y ~ x&#39; . 7. Adding a logarithmic scale . From the plot above, we can see a straight line does not fit well at all, and the rest of the world is growing much faster than linearly. What if we added a logarithmic scale to the y-axis? . plt_not_china_trend_lin + scale_y_log10(TRUE) . `geom_smooth()` using formula &#39;y ~ x&#39; . 8. Which countries outside of China have been hit hardest? . With the logarithmic scale, we get a much closer fit to the data. From a data science point of view, a good fit is great news. Unfortunately, from a public health point of view, that means that cases of COVID-19 in the rest of the world are growing at an exponential rate, which is terrible news. . Not all countries are being affected by COVID-19 equally, and it would be helpful to know where in the world the problems are greatest. Let&#39;s find the countries outside of China with the most confirmed cases in our dataset. . confirmed_cases_by_country &lt;- read_csv(&quot;datasets/confirmed_cases_by_country.csv&quot;) glimpse(confirmed_cases_by_country) # Group by country, summarize to calculate total cases, find the top 7 top_countries_by_total_cases &lt;- confirmed_cases_by_country %&gt;% group_by(country) %&gt;% summarise(confirmed_cases_by_country = max(cum_cases)) %&gt;% top_n(7) # See the result top_countries_by_total_cases . Parsed with column specification: cols( country = col_character(), province = col_character(), date = col_date(format = &#34;&#34;), cases = col_double(), cum_cases = col_double() ) . Observations: 13,272 Variables: 5 $ country &lt;chr&gt; &#34;Afghanistan&#34;, &#34;Albania&#34;, &#34;Algeria&#34;, &#34;Andorra&#34;, &#34;Antigua ... $ province &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... $ date &lt;date&gt; 2020-01-22, 2020-01-22, 2020-01-22, 2020-01-22, 2020-01-... $ cases &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... $ cum_cases &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... . Selecting by confirmed_cases_by_country . A tibble: 7 x 2 countryconfirmed_cases_by_country . &lt;chr&gt;&lt;dbl&gt; . France | 7699 | . Germany | 9257 | . Iran | 16169 | . Italy | 31506 | . Korea, South | 8320 | . Spain | 11748 | . US | 6421 | . 9. Plotting hardest hit countries as of Mid-March 2020 . Even though the outbreak was first identified in China, there is only one country from East Asia (South Korea) in the above table. Four of the listed countries (France, Germany, Italy, and Spain) are in Europe and share borders. To get more context, we can plot these countries&#39; confirmed cases over time. . Finally, congratulations on getting to the last step! If you would like to continue making visualizations or find the hardest hit countries as of today, you can do your own analyses with the latest data available here. . confirmed_cases_top7_outside_china = read_csv(&#39;datasets/confirmed_cases_top7_outside_china.csv&#39;) # glimpse(confirmed_cases_top7_outside_china) # Using confirmed_cases_top7_outside_china, draw a line plot of # cum_cases vs. date, grouped and colored by country ggplot(data=confirmed_cases_top7_outside_china, aes(x=date, y=cum_cases)) + geom_line(aes(color=country, group=country)) + ylab(&quot;Cumulative confirmed cases&quot;) . Parsed with column specification: cols( country = col_character(), date = col_date(format = &#34;&#34;), cum_cases = col_double() ) . Observations: 2,030 Variables: 3 $ country &lt;chr&gt; &#34;Germany&#34;, &#34;Iran&#34;, &#34;Italy&#34;, &#34;Korea, South&#34;, &#34;Spain&#34;, &#34;US&#34;... $ date &lt;date&gt; 2020-02-18, 2020-02-18, 2020-02-18, 2020-02-18, 2020-02-... $ cum_cases &lt;dbl&gt; 16, 0, 3, 31, 2, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, ... .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/r/2020/04/03/Visualizing-COVID-19.html",
            "relUrl": "/datacamp/projects/r/2020/04/03/Visualizing-COVID-19.html",
            "date": " • Apr 3, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Introduction to DataCamp Projects(R)",
            "content": "1. This is a Jupyter notebook! . A Jupyter notebook is a document that contains text cells (what you&#39;re reading right now) and code cells. What is special with a notebook is that it&#39;s interactive: You can change or add code cells, and then run a cell by first selecting it and then clicking the run cell button above ( ▶| Run ) or hitting ctrl + enter. . . The result will be displayed directly in the notebook. You could use a notebook as a simple calculator. For example, it&#39;s estimated that on average 256 children were born every minute in 2016. The code cell below calculates how many children were born on average on a day. . 256 * 60 * 24 # Children × minutes × hours . 368640 2. Put any code in code cells . But a code cell can contain much more than a simple one-liner! This is a notebook running R and you can put any R code in a code cell (but notebooks can run other languages too, like python). Below is a code cell where we define a whole new function (greet). To show the output of greet we can run it anywhere and the result is always printed out at the end of the code cell. . greet &lt;- function(first_name, last_name) { paste(&quot;My name is &quot;, last_name, &quot;, &quot;, first_name, &quot; &quot;, last_name, &quot;!&quot;, sep = &quot;&quot;) } # Replace with your first and last name. # That is, unless your name is already James Bond. greet(&quot;James&quot;, &quot;Bond&quot;) . &#39;My name is Bond, James Bond!&#39; 3. Jupyter notebooks &#9825; data . We&#39;ve seen that notebooks can display basic objects such as numbers and strings. But notebooks also support the objects used in data science, which makes them great for interactive data analysis! . For example, below we create a data frame by reading in a csv-file with the average global temperature for the years 1850 to 2016. If we look at the head of this data frame the notebook will render it as a nice-looking table. . global_temp &lt;- read.csv(&quot;datasets/global_temperature.csv&quot;) # Take a look at the first datapoints global_temp[1,] . A data.frame: 1 x 2 yeardegrees_celsius . &lt;int&gt;&lt;dbl&gt; . 1850 | 7.74 | . 4. Jupyter notebooks &#9825; plots . Tables are nice but — as the saying goes — &quot;a plot can show a thousand data points&quot;. Notebooks handle plots as well and all plots created in code cells will automatically be displayed inline. . Let&#39;s take a look at the global temperature for the last 150 years. . plot(global_temp$year, global_temp$degrees_celsius, type = &quot;l&quot;, col = &quot;forestgreen&quot;, xlab = &quot;Year&quot;, ylab = &quot;Celsius&quot;) . 5. Jupyter notebooks &#9825; Data Science . Tables and plots are the most common outputs when doing data science and, as these outputs are rendered inline, notebooks works great not only for doing a data analysis but also for showing a data analysis. A finished notebook contains both the result and the code that produced it. This is useful when you want to share your findings or if you need to update your analysis with new data. . Let&#39;s add some advanced data analysis to our notebook! For example, this (slightly complicated) code forecasts the global temperature 50 years into the future using an exponential smoothing state space model (ets). . Note: Global temperature is a complex phenomenon and exponential smoothing is likely not a good model here. This is just an example of how easy it is to do (and show) complex forecasting in a Jupyter notebook. . library(forecast) library(ggplot2) # Converting global_temp into a time series (ts) object. global_temp_ts &lt;- ts(global_temp$degrees_celsius, start = global_temp$year[1]) # Forecasting global temperature 50 years into the future # using an exponential smoothing state space model (ets). temperature_forecast &lt;- forecast( ets(global_temp_ts), h = 50) # Plotting the forecast plot(temperature_forecast, type=&#39;l&#39;) . 6. Goodbye for now! . This was just a short introduction to Jupyter notebooks, an open source technology that is increasingly used for data science and analysis. I hope you enjoyed it! :) . I_am_ready &lt;- TRUE # Ps. # Feel free to try out any other stuff in this notebook. # It&#39;s all yours! .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/r/2020/03/01/Introduction-to-DataCamp-Projects.html",
            "relUrl": "/datacamp/projects/r/2020/03/01/Introduction-to-DataCamp-Projects.html",
            "date": " • Mar 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Introduction to DataCamp Projects(SQL)",
            "content": "1. This is a Jupyter Notebook! . A Jupyter Notebook is a document that contains text cells (what you&#39;re reading right now) and code cells. What is special with a notebook is that it&#39;s interactive: You can change or add code cells, and then run a cell by first selecting it and then clicking the run cell button above ( ▶| Run ) or hitting Ctrl + Enter. . . The result will be displayed directly in the notebook. You could use a notebook as a simple calculator. For example, it&#39;s estimated that on average 256 children were born every minute in 2016. The code cell below calculates how many children were born on average on a day. . 256 * 60 * 24 # Children × minutes × hours . 368640 . 2. Put any code in code cells . But a code cell can contain much more than a simple one-liner! This is a notebook running Python and you can put any Python code in a code cell (but notebooks can run other languages too, like R). Below is a code cell where we define a whole new function (greet). To show the output of greet we run it last in the code cell as the last value is always printed out. . def greet(first_name, last_name): greeting = &#39;My name is &#39; + last_name + &#39;, &#39; + first_name + &#39; &#39; + last_name + &#39;!&#39; return greeting # Replace with your first and last name. # That is, unless your name is already Jane Bond. greet(&#39;Anurag&#39;, &#39;Peddi&#39;) . &#39;My name is Peddi, Anurag Peddi!&#39; . 3. Jupyter Notebooks &#9825; SQL (part i) . We&#39;ve seen that notebooks can display basic objects such as numbers and strings. But notebooks also support and display the outputs of SQL commands! Using an open source Jupyter extension called ipython-sql, we can connect to a database and issue SQL commands within our notebook. For example, we can connect to a PostgreSQL database that has a table that contains country data, then inspect the first three rows of the table by putting %%sql ahead of the SQL commands (more on the meaning of %% later). . %%sql postgresql:///countries SELECT * FROM countries LIMIT 3; . 3 rows affected. . code name continent region surface_area indep_year local_name gov_form capital cap_long cap_lat . AFG | Afghanistan | Asia | Southern and Central Asia | 652090.0 | 1919 | Afganistan/Afqanestan | Islamic Emirate | Kabul | 69.1761 | 34.5228 | . NLD | Netherlands | Europe | Western Europe | 41526.0 | 1581 | Nederland | Constitutional Monarchy | Amsterdam | 4.89095 | 52.3738 | . ALB | Albania | Europe | Southern Europe | 28748.0 | 1912 | Shqiperia | Republic | Tirane | 19.8172 | 41.3317 | . 4. Jupyter Notebooks &#9825; SQL (part ii) . And after the first connection to the database, the connection code (postgresql:///countries) can be omitted. Let&#39;s do a different query this time and select the row in the countries table for Belgium. Note the single % this time. Again, more on that later. . %sql SELECT * FROM countries where name = &#39;Belgium&#39;; . * postgresql:///countries 1 rows affected. . code name continent region surface_area indep_year local_name gov_form capital cap_long cap_lat . BEL | Belgium | Europe | Western Europe | 30518.0 | 1830 | Belgie/Belgique | Constitutional Monarchy, Federation | Brussels | 4.36761 | 50.8371 | . 5. Jupyter Notebooks &#9825; SQL (part iii) . We can even convert our SQL results to a pandas DataFrame! Let&#39;s convert the entire countries table. . result = %sql SELECT * FROM countries; # To pandas DataFrame df = result.DataFrame() df.info() . * postgresql:///countries 206 rows affected. &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 206 entries, 0 to 205 Data columns (total 11 columns): code 206 non-null object name 206 non-null object continent 206 non-null object region 206 non-null object surface_area 206 non-null float64 indep_year 188 non-null float64 local_name 206 non-null object gov_form 206 non-null object capital 201 non-null object cap_long 204 non-null float64 cap_lat 204 non-null float64 dtypes: float64(4), object(7) memory usage: 17.8+ KB . 6. Jupyter Notebooks &#9825; SQLAlchemy . If SQLAlchemy is your thing, you can do that in this notebook, too! Jupyter Notebooks love everything, apparently... . What&#39;s SQLAlchemy, you ask? SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL. Next, we&#39;ll run the last query we just ran except after connecting to and querying the database using SQLAlchemy. . from sqlalchemy import create_engine engine = create_engine(&quot;postgresql:///countries&quot;); # Query database result = engine.execute(&quot;SELECT * FROM countries;&quot;) # Display column names result.keys() . [&#39;code&#39;, &#39;name&#39;, &#39;continent&#39;, &#39;region&#39;, &#39;surface_area&#39;, &#39;indep_year&#39;, &#39;local_name&#39;, &#39;gov_form&#39;, &#39;capital&#39;, &#39;cap_long&#39;, &#39;cap_lat&#39;] . 7. Jupyter Notebooks &#9825; plots . Tables are nice but — as the saying goes — &quot;a plot can show a thousand data points.&quot; Notebooks handle plots as well, but it requires some more magic. Here magic does not refer to any arcane rituals but to so-called &quot;magic commands&quot; that affect how the Jupyter Notebook works. Magic commands start with either % or %% (just like we saw with %sql and %%sql) and the command we need to nicely display plots inline is %matplotlib inline. With this magic in place, all plots created in code cells will automatically be displayed inline. . Using the previously created pandas DataFrame that we named df, let&#39;s plot the number of countries in each continent as a bar chart using the plot() method of pandas DataFrames. . Now, for the difference between %%sql and %sql: ordinary assignment works for single-line %sql queries while %%sql is for multi-line queries. See the Assignment ipython-sql documentation section for more info. . %matplotlib inline # Plotting number of countries in each continent df.continent.value_counts().plot(kind=&#39;bar&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff916880668&gt; . 8. Goodbye for now! . Tables and plots are the most common outputs when doing data analysis, but Jupyter Notebooks can render many more types of outputs such as sound, animation, video, etc. Yes, almost anything that can be shown in a modern web browser. This also makes it possible to include interactive widgets directly in the notebook! Everything in this collection of Jupyter Widgets can be displayed in this notebook. . But that&#39;s enough for now! This was just a short introduction to Jupyter Notebooks, an open source technology that is increasingly used for data science and analysis. We hope you enjoyed it! :) . I_am_ready = True # P.S. Feel free to try out any other stuff in this notebook. # It&#39;s all yours! .",
            "url": "https://anuraganalog.github.io/blog/datacamp/projects/sql/2020/01/25/Introduction-to-DataCamp-Projects.html",
            "relUrl": "/datacamp/projects/sql/2020/01/25/Introduction-to-DataCamp-Projects.html",
            "date": " • Jan 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://anuraganalog.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://anuraganalog.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}